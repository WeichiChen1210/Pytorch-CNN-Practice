{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch homework\n",
    "## 作業說明\n",
    "這次的作業總共有5個部份，在每一個部份會有一些被註解框起來的區塊需要完成。\n",
    "1. Preparation: 我們會利用CIFAR-10 dataset **(10%)**\n",
    "2. Pytorch Module API: 在這邊我們會利用 nn.Module 建構出簡單的CNN（CNN架構請參照我們所提供） **(20%)**\n",
    "3. Pytorch ModuleList API: 在這邊我們 nn.ModuleList 以及 nn.Module來建構出簡單的CNN（CNN架構請參照我們所提供） **(20%)**\n",
    "4. Pytorch Sequential API: 在這邊我們 nn.Sequential 來建構出簡單的CNN（CNN架構請參照我們所提供） **(20%)**\n",
    "5. CIFAR-10 open-ended challenge: 在這邊請大家建構屬於自己的CNN，並且盡量的得到高準確度，並解釋如何建構的 **(30%)**\n",
    "    * 可以嘗試建構任意的layer, optimizer或是 hyperparameters等\n",
    "    * 由於並不是所有同學都有GPU可以提供training，因此這題分數的分配不是根據最後的準確度而給分，而是達到baseline之後便會給於全部的分數\n",
    "    * **Baseline: 65% on testing data**\n",
    "    \n",
    "## 作業繳交\n",
    "* Deadline : 11/06 中午12:00\n",
    "    * **遲交一天的打7折**\n",
    "    * **遲交一天以上的打5折**\n",
    "* 繳交方式 : 請繳交這個ipynb檔至moodle\n",
    "* 作業命名 : (你的學號)\\_(姓名)\\_hw2.ipynb  (ex.F71112222_人工智.ipynb) \n",
    "    * **格式不對的話會扣10分！！！**\n",
    "* 有任何問題歡迎寄信至我的信箱\n",
    "    * 黃顯堯 e0928021388@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "你可以根據需求調整epochs, batch size等等的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "CIFAR_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 49000\n",
    "\n",
    "CUDA = True\n",
    "\n",
    "PATH_TO_SAVE_DATA = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "                  ])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=PATH_TO_SAVE_DATA, train=True,\n",
    "                              download=True, transform=data_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                          sampler=SubsetRandomSampler(range(TRAIN_NUMS)))\n",
    "val_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        sampler=SubsetRandomSampler(range(TRAIN_NUMS, 50000)))\n",
    "\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(root=PATH_TO_SAVE_DATA, train=False,\n",
    "                             download=True, transform=data_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU setting\n",
    "可以根據選擇是否要使用gpu，在本次的作業沒有一定要使用到gpu，假如你沒有安裝cuda，torch.cuda.is_available會return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "我們有提供Trainer讓同學可以training自己建構的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(\"---------------- Epoch {} ----------------\".format(epoch))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        \n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "                \n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening: torch.Size([10, 3, 32, 32])\n",
      "After flattening: torch.Size([10, 3072])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):    \n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "#     x = x.view(x.shape[0], x.shape[1]*x.shape[2]*x.shape[3])\n",
    "    return x\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.zeros((10, 3, 32, 32))\n",
    "    print(\"Before flattening:\", x.shape)\n",
    "    print(\"After flattening:\", flatten(x).shape) # Expected output (10, 3072) \n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 : Module API\n",
    "In this part, you have to complete the implentation of CNN with Module API.\n",
    "The network should have the following architectures.\n",
    "1. A convolution layer with 16 3\\*3 filters, with stride 2\n",
    "2. ReLU\n",
    "3. A convolution layer with 32 3\\*3 filters, with stride 2\n",
    "4. ReLU\n",
    "5. Flatten\n",
    "6. A fully-connected layer produce tensor to 200 \n",
    "7. ReLU\n",
    "8. A fully-connected layer produce score to 10 (classes)\n",
    "![](./resource/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"537pt\"\n",
       " viewBox=\"0.00 0.00 335.50 537.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 533)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-533 331.5,-533 331.5,4 -4,4\"/>\n",
       "<!-- 140319472251120 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140319472251120</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"282.5,-21 197.5,-21 197.5,0 282.5,0 282.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140317015616424 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140317015616424</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"236,-78 142,-78 142,-57 236,-57 236,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140317015616424&#45;&gt;140319472251120 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140317015616424&#45;&gt;140319472251120</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.5927,-56.7787C205.6449,-48.8969 215.3997,-37.9944 223.6699,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.3907,-30.9594 230.4503,-21.1732 221.174,-26.2918 226.3907,-30.9594\"/>\n",
       "</g>\n",
       "<!-- 140317015616760 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140317015616760</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231.5,-141.5 146.5,-141.5 146.5,-120.5 231.5,-120.5 231.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140317015616760&#45;&gt;140317015616424 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140317015616760&#45;&gt;140317015616424</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189,-120.2281C189,-111.5091 189,-98.9699 189,-88.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.5001,-88.1128 189,-78.1128 185.5001,-88.1129 192.5001,-88.1128\"/>\n",
       "</g>\n",
       "<!-- 140317015614016 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140317015614016</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"190.5,-205 77.5,-205 77.5,-184 190.5,-184 190.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140317015614016&#45;&gt;140317015616760 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140317015614016&#45;&gt;140317015616760</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.33,-183.7281C151.4383,-174.3667 163.3611,-160.6012 172.9914,-149.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"175.9063,-151.4632 179.8078,-141.6128 170.6151,-146.8802 175.9063,-151.4632\"/>\n",
       "</g>\n",
       "<!-- 140317015614632 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140317015614632</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"181,-268.5 87,-268.5 87,-247.5 181,-247.5 181,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140317015614632&#45;&gt;140317015614016 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140317015614632&#45;&gt;140317015614016</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-247.2281C134,-238.5091 134,-225.9699 134,-215.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-215.1128 134,-205.1128 130.5001,-215.1129 137.5001,-215.1128\"/>\n",
       "</g>\n",
       "<!-- 140317015614184 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140317015614184</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"215,-332 53,-332 53,-311 215,-311 215,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140317015614184&#45;&gt;140317015614632 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140317015614184&#45;&gt;140317015614632</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-310.7281C134,-302.0091 134,-289.4699 134,-278.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-278.6128 134,-268.6128 130.5001,-278.6129 137.5001,-278.6128\"/>\n",
       "</g>\n",
       "<!-- 140317015617264 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140317015617264</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-395.5 34,-395.5 34,-374.5 128,-374.5 128,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140317015617264&#45;&gt;140317015614184 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140317015617264&#45;&gt;140317015614184</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.9907,-374.2281C97.8042,-364.8667 109.2935,-351.1012 118.5736,-339.9826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.4213,-342.0328 125.1421,-332.1128 116.0472,-337.5474 121.4213,-342.0328\"/>\n",
       "</g>\n",
       "<!-- 140317015614296 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140317015614296</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-459 0,-459 0,-438 162,-438 162,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140317015614296&#45;&gt;140317015617264 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140317015614296&#45;&gt;140317015617264</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-437.7281C81,-429.0091 81,-416.4699 81,-405.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-405.6128 81,-395.6128 77.5001,-405.6129 84.5001,-405.6128\"/>\n",
       "</g>\n",
       "<!-- 140317015613736 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140317015613736</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"121.5,-529 40.5,-529 40.5,-495 121.5,-495 121.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140317015613736&#45;&gt;140317015614296 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140317015613736&#45;&gt;140317015614296</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-494.9832C81,-487.1157 81,-477.6973 81,-469.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-469.3686 81,-459.3687 77.5001,-469.3687 84.5001,-469.3686\"/>\n",
       "</g>\n",
       "<!-- 140317015617320 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140317015617320</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"227.5,-402 146.5,-402 146.5,-368 227.5,-368 227.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140317015617320&#45;&gt;140317015614184 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140317015617320&#45;&gt;140317015614184</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.797,-367.9832C165.6401,-359.4085 156.9458,-348.9916 149.603,-340.1942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.1664,-337.8032 143.0715,-332.3687 146.7923,-342.2887 152.1664,-337.8032\"/>\n",
       "</g>\n",
       "<!-- 140317015617488 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140317015617488</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"281.5,-205 208.5,-205 208.5,-184 281.5,-184 281.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140317015617488&#45;&gt;140317015616760 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140317015617488&#45;&gt;140317015616760</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.5004,-183.7281C227.1637,-174.2749 214.8666,-160.3309 205.0119,-149.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.5987,-146.7979 198.3593,-141.6128 202.3486,-151.428 207.5987,-146.7979\"/>\n",
       "</g>\n",
       "<!-- 140317015617432 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140317015617432</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"282.5,-275 207.5,-275 207.5,-241 282.5,-241 282.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (200, 1568)</text>\n",
       "</g>\n",
       "<!-- 140317015617432&#45;&gt;140317015617488 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140317015617432&#45;&gt;140317015617488</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245,-240.9832C245,-233.1157 245,-223.6973 245,-215.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.5001,-215.3686 245,-205.3687 241.5001,-215.3687 248.5001,-215.3686\"/>\n",
       "</g>\n",
       "<!-- 140317015614520 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140317015614520</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"327.5,-78 254.5,-78 254.5,-57 327.5,-57 327.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140317015614520&#45;&gt;140319472251120 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140317015614520&#45;&gt;140319472251120</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.4073,-56.7787C274.3551,-48.8969 264.6003,-37.9944 256.3301,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.826,-26.2918 249.5497,-21.1732 253.6093,-30.9594 258.826,-26.2918\"/>\n",
       "</g>\n",
       "<!-- 140317015613960 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140317015613960</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"324.5,-148 257.5,-148 257.5,-114 324.5,-114 324.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 200)</text>\n",
       "</g>\n",
       "<!-- 140317015613960&#45;&gt;140317015614520 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140317015613960&#45;&gt;140317015614520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291,-113.9832C291,-106.1157 291,-96.6973 291,-88.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.5001,-88.3686 291,-78.3687 287.5001,-88.3687 294.5001,-88.3686\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f9eac3917b8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1, self.conv2 = None, None\n",
    "        self.fc1, self.fc2 = None, None\n",
    "        ###############################################################################\n",
    "        #       TODO : Set up the layer that you need to construct the model          #\n",
    "        ###############################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, bias=0)\n",
    "#         self.conv4 = nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, stride=1, bias=0)\n",
    "#         self.conv5 = nn.Conv2d(in_channels=96, out_channels=128, kernel_size=3, stride=2, bias=0)\n",
    "#         self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, bias=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32*7*7, 200, bias=0)\n",
    "        self.fc2 = nn.Linear(200, 10, bias=0)\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        ###############################################################################\n",
    "        #            TODO : Implement the forward function. You should use            #\n",
    "        #                   the layers you defined in __init__ and specify the        #\n",
    "        #                   connectivity of those layers in forward()                 #\n",
    "        ###############################################################################\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "#         print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "#         print(x.shape)\n",
    "#         x = F.relu(self.conv3(x))\n",
    "#         print(x.shape)\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         print(x.shape)\n",
    "#         x = F.relu(self.conv5(x))\n",
    "#         print(x.shape)\n",
    "#         x = F.relu(self.conv6(x))\n",
    "#         print(x.shape)\n",
    "        x = flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################\n",
    "    \n",
    "        return out\n",
    "        \n",
    "\n",
    "model = CNN()\n",
    "x = torch.zeros((BATCH_SIZE, 3, 32, 32))\n",
    "make_dot(model(x), params=dict(model.named_parameters())) # You can check if the picture is the same \n",
    "                                                          # as previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Train the model and check the accuracy of training dataset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.303 Acc 0.047\n",
      "[  1/25] Training Step 100 Loss 2.302 Acc 0.125\n",
      "[  1/25] Training Step 200 Loss 2.303 Acc 0.094\n",
      "[  1/25] Training Step 300 Loss 2.302 Acc 0.109\n",
      "[  1/25] Training Step 400 Loss 2.301 Acc 0.141\n",
      "[  1/25] Training Step 500 Loss 2.300 Acc 0.234\n",
      "[  1/25] Training Step 600 Loss 2.298 Acc 0.125\n",
      "[  1/25] Training Step 700 Loss 2.296 Acc 0.172\n",
      "[  1/25] Validate Step 015 Loss 2.285 Acc 0.200\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 2.291 Acc 0.141\n",
      "[  2/25] Training Step 100 Loss 2.248 Acc 0.219\n",
      "[  2/25] Training Step 200 Loss 2.116 Acc 0.328\n",
      "[  2/25] Training Step 300 Loss 1.993 Acc 0.266\n",
      "[  2/25] Training Step 400 Loss 1.883 Acc 0.281\n",
      "[  2/25] Training Step 500 Loss 2.078 Acc 0.234\n",
      "[  2/25] Training Step 600 Loss 2.008 Acc 0.312\n",
      "[  2/25] Training Step 700 Loss 1.984 Acc 0.328\n",
      "[  2/25] Validate Step 015 Loss 1.950 Acc 0.290\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.881 Acc 0.453\n",
      "[  3/25] Training Step 100 Loss 1.904 Acc 0.359\n",
      "[  3/25] Training Step 200 Loss 2.005 Acc 0.281\n",
      "[  3/25] Training Step 300 Loss 1.833 Acc 0.422\n",
      "[  3/25] Training Step 400 Loss 1.930 Acc 0.281\n",
      "[  3/25] Training Step 500 Loss 1.891 Acc 0.344\n",
      "[  3/25] Training Step 600 Loss 1.839 Acc 0.328\n",
      "[  3/25] Training Step 700 Loss 1.839 Acc 0.359\n",
      "[  3/25] Validate Step 015 Loss 1.700 Acc 0.395\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.713 Acc 0.406\n",
      "[  4/25] Training Step 100 Loss 1.619 Acc 0.391\n",
      "[  4/25] Training Step 200 Loss 1.492 Acc 0.469\n",
      "[  4/25] Training Step 300 Loss 1.501 Acc 0.500\n",
      "[  4/25] Training Step 400 Loss 1.605 Acc 0.469\n",
      "[  4/25] Training Step 500 Loss 1.679 Acc 0.359\n",
      "[  4/25] Training Step 600 Loss 1.573 Acc 0.469\n",
      "[  4/25] Training Step 700 Loss 1.674 Acc 0.438\n",
      "[  4/25] Validate Step 015 Loss 1.548 Acc 0.443\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.695 Acc 0.453\n",
      "[  5/25] Training Step 100 Loss 1.516 Acc 0.531\n",
      "[  5/25] Training Step 200 Loss 1.485 Acc 0.422\n",
      "[  5/25] Training Step 300 Loss 1.519 Acc 0.516\n",
      "[  5/25] Training Step 400 Loss 1.336 Acc 0.562\n",
      "[  5/25] Training Step 500 Loss 1.286 Acc 0.562\n",
      "[  5/25] Training Step 600 Loss 1.569 Acc 0.453\n",
      "[  5/25] Training Step 700 Loss 1.743 Acc 0.422\n",
      "[  5/25] Validate Step 015 Loss 1.489 Acc 0.465\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.415 Acc 0.562\n",
      "[  6/25] Training Step 100 Loss 1.314 Acc 0.531\n",
      "[  6/25] Training Step 200 Loss 1.170 Acc 0.562\n",
      "[  6/25] Training Step 300 Loss 1.316 Acc 0.547\n",
      "[  6/25] Training Step 400 Loss 1.513 Acc 0.391\n",
      "[  6/25] Training Step 500 Loss 1.504 Acc 0.500\n",
      "[  6/25] Training Step 600 Loss 1.411 Acc 0.469\n",
      "[  6/25] Training Step 700 Loss 1.147 Acc 0.625\n",
      "[  6/25] Validate Step 015 Loss 1.422 Acc 0.491\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.395 Acc 0.547\n",
      "[  7/25] Training Step 100 Loss 1.188 Acc 0.562\n",
      "[  7/25] Training Step 200 Loss 1.319 Acc 0.578\n",
      "[  7/25] Training Step 300 Loss 1.228 Acc 0.625\n",
      "[  7/25] Training Step 400 Loss 1.307 Acc 0.562\n",
      "[  7/25] Training Step 500 Loss 1.246 Acc 0.547\n",
      "[  7/25] Training Step 600 Loss 1.191 Acc 0.625\n",
      "[  7/25] Training Step 700 Loss 1.482 Acc 0.547\n",
      "[  7/25] Validate Step 015 Loss 1.344 Acc 0.526\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 1.165 Acc 0.500\n",
      "[  8/25] Training Step 100 Loss 1.599 Acc 0.438\n",
      "[  8/25] Training Step 200 Loss 1.310 Acc 0.484\n",
      "[  8/25] Training Step 300 Loss 1.684 Acc 0.406\n",
      "[  8/25] Training Step 400 Loss 1.549 Acc 0.438\n",
      "[  8/25] Training Step 500 Loss 1.366 Acc 0.500\n",
      "[  8/25] Training Step 600 Loss 1.052 Acc 0.688\n",
      "[  8/25] Training Step 700 Loss 1.243 Acc 0.547\n",
      "[  8/25] Validate Step 015 Loss 1.274 Acc 0.563\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 1.334 Acc 0.547\n",
      "[  9/25] Training Step 100 Loss 1.322 Acc 0.516\n",
      "[  9/25] Training Step 200 Loss 1.169 Acc 0.641\n",
      "[  9/25] Training Step 300 Loss 1.233 Acc 0.562\n",
      "[  9/25] Training Step 400 Loss 1.334 Acc 0.516\n",
      "[  9/25] Training Step 500 Loss 1.422 Acc 0.516\n",
      "[  9/25] Training Step 600 Loss 1.417 Acc 0.562\n",
      "[  9/25] Training Step 700 Loss 1.159 Acc 0.594\n",
      "[  9/25] Validate Step 015 Loss 1.261 Acc 0.555\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 0.880 Acc 0.688\n",
      "[ 10/25] Training Step 100 Loss 1.179 Acc 0.609\n",
      "[ 10/25] Training Step 200 Loss 1.165 Acc 0.594\n",
      "[ 10/25] Training Step 300 Loss 1.068 Acc 0.656\n",
      "[ 10/25] Training Step 400 Loss 1.222 Acc 0.500\n",
      "[ 10/25] Training Step 500 Loss 1.330 Acc 0.547\n",
      "[ 10/25] Training Step 600 Loss 1.145 Acc 0.547\n",
      "[ 10/25] Training Step 700 Loss 0.914 Acc 0.688\n",
      "[ 10/25] Validate Step 015 Loss 1.210 Acc 0.596\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 1.126 Acc 0.594\n",
      "[ 11/25] Training Step 100 Loss 1.116 Acc 0.609\n",
      "[ 11/25] Training Step 200 Loss 1.120 Acc 0.609\n",
      "[ 11/25] Training Step 300 Loss 0.813 Acc 0.734\n",
      "[ 11/25] Training Step 400 Loss 1.240 Acc 0.578\n",
      "[ 11/25] Training Step 500 Loss 1.190 Acc 0.656\n",
      "[ 11/25] Training Step 600 Loss 1.040 Acc 0.625\n",
      "[ 11/25] Training Step 700 Loss 1.046 Acc 0.641\n",
      "[ 11/25] Validate Step 015 Loss 1.197 Acc 0.590\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 0.999 Acc 0.672\n",
      "[ 12/25] Training Step 100 Loss 0.971 Acc 0.672\n",
      "[ 12/25] Training Step 200 Loss 1.112 Acc 0.609\n",
      "[ 12/25] Training Step 300 Loss 0.909 Acc 0.703\n",
      "[ 12/25] Training Step 400 Loss 0.877 Acc 0.625\n",
      "[ 12/25] Training Step 500 Loss 0.926 Acc 0.672\n",
      "[ 12/25] Training Step 600 Loss 1.279 Acc 0.609\n",
      "[ 12/25] Training Step 700 Loss 0.805 Acc 0.750\n",
      "[ 12/25] Validate Step 015 Loss 1.199 Acc 0.596\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.896 Acc 0.656\n",
      "[ 13/25] Training Step 100 Loss 0.790 Acc 0.719\n",
      "[ 13/25] Training Step 200 Loss 0.864 Acc 0.656\n",
      "[ 13/25] Training Step 300 Loss 0.925 Acc 0.688\n",
      "[ 13/25] Training Step 400 Loss 1.022 Acc 0.609\n",
      "[ 13/25] Training Step 500 Loss 0.893 Acc 0.641\n",
      "[ 13/25] Training Step 600 Loss 0.912 Acc 0.641\n",
      "[ 13/25] Training Step 700 Loss 0.696 Acc 0.812\n",
      "[ 13/25] Validate Step 015 Loss 1.192 Acc 0.590\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 0.543 Acc 0.812\n",
      "[ 14/25] Training Step 100 Loss 0.639 Acc 0.750\n",
      "[ 14/25] Training Step 200 Loss 0.956 Acc 0.688\n",
      "[ 14/25] Training Step 300 Loss 0.858 Acc 0.719\n",
      "[ 14/25] Training Step 400 Loss 0.837 Acc 0.641\n",
      "[ 14/25] Training Step 500 Loss 0.803 Acc 0.719\n",
      "[ 14/25] Training Step 600 Loss 0.792 Acc 0.703\n",
      "[ 14/25] Training Step 700 Loss 0.778 Acc 0.750\n",
      "[ 14/25] Validate Step 015 Loss 1.317 Acc 0.559\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.802 Acc 0.766\n",
      "[ 15/25] Training Step 100 Loss 0.696 Acc 0.750\n",
      "[ 15/25] Training Step 200 Loss 0.788 Acc 0.750\n",
      "[ 15/25] Training Step 300 Loss 0.832 Acc 0.656\n",
      "[ 15/25] Training Step 400 Loss 0.748 Acc 0.703\n",
      "[ 15/25] Training Step 500 Loss 0.606 Acc 0.766\n",
      "[ 15/25] Training Step 600 Loss 0.671 Acc 0.719\n",
      "[ 15/25] Training Step 700 Loss 0.790 Acc 0.703\n",
      "[ 15/25] Validate Step 015 Loss 1.239 Acc 0.599\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.730 Acc 0.734\n",
      "[ 16/25] Training Step 100 Loss 0.844 Acc 0.750\n",
      "[ 16/25] Training Step 200 Loss 0.508 Acc 0.859\n",
      "[ 16/25] Training Step 300 Loss 0.601 Acc 0.781\n",
      "[ 16/25] Training Step 400 Loss 0.706 Acc 0.750\n",
      "[ 16/25] Training Step 500 Loss 0.873 Acc 0.688\n",
      "[ 16/25] Training Step 600 Loss 0.774 Acc 0.750\n",
      "[ 16/25] Training Step 700 Loss 0.649 Acc 0.750\n",
      "[ 16/25] Validate Step 015 Loss 1.274 Acc 0.619\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.736 Acc 0.734\n",
      "[ 17/25] Training Step 100 Loss 0.526 Acc 0.812\n",
      "[ 17/25] Training Step 200 Loss 0.754 Acc 0.719\n",
      "[ 17/25] Training Step 300 Loss 0.580 Acc 0.797\n",
      "[ 17/25] Training Step 400 Loss 0.502 Acc 0.812\n",
      "[ 17/25] Training Step 500 Loss 0.627 Acc 0.797\n",
      "[ 17/25] Training Step 600 Loss 0.942 Acc 0.656\n",
      "[ 17/25] Training Step 700 Loss 0.658 Acc 0.781\n",
      "[ 17/25] Validate Step 015 Loss 1.371 Acc 0.605\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 0.490 Acc 0.812\n",
      "[ 18/25] Training Step 100 Loss 0.490 Acc 0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.452 Acc 0.859\n",
      "[ 18/25] Training Step 300 Loss 0.586 Acc 0.797\n",
      "[ 18/25] Training Step 400 Loss 0.373 Acc 0.875\n",
      "[ 18/25] Training Step 500 Loss 0.436 Acc 0.828\n",
      "[ 18/25] Training Step 600 Loss 0.609 Acc 0.797\n",
      "[ 18/25] Training Step 700 Loss 0.483 Acc 0.797\n",
      "[ 18/25] Validate Step 015 Loss 1.431 Acc 0.585\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.511 Acc 0.828\n",
      "[ 19/25] Training Step 100 Loss 0.307 Acc 0.875\n",
      "[ 19/25] Training Step 200 Loss 0.364 Acc 0.859\n",
      "[ 19/25] Training Step 300 Loss 0.392 Acc 0.859\n",
      "[ 19/25] Training Step 400 Loss 0.453 Acc 0.844\n",
      "[ 19/25] Training Step 500 Loss 0.603 Acc 0.828\n",
      "[ 19/25] Training Step 600 Loss 0.445 Acc 0.875\n",
      "[ 19/25] Training Step 700 Loss 0.314 Acc 0.891\n",
      "[ 19/25] Validate Step 015 Loss 1.587 Acc 0.571\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.407 Acc 0.828\n",
      "[ 20/25] Training Step 100 Loss 0.336 Acc 0.906\n",
      "[ 20/25] Training Step 200 Loss 0.413 Acc 0.859\n",
      "[ 20/25] Training Step 300 Loss 0.288 Acc 0.906\n",
      "[ 20/25] Training Step 400 Loss 0.387 Acc 0.891\n",
      "[ 20/25] Training Step 500 Loss 0.259 Acc 0.922\n",
      "[ 20/25] Training Step 600 Loss 0.460 Acc 0.875\n",
      "[ 20/25] Training Step 700 Loss 0.317 Acc 0.875\n",
      "[ 20/25] Validate Step 015 Loss 1.703 Acc 0.583\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.323 Acc 0.891\n",
      "[ 21/25] Training Step 100 Loss 0.147 Acc 0.969\n",
      "[ 21/25] Training Step 200 Loss 0.374 Acc 0.844\n",
      "[ 21/25] Training Step 300 Loss 0.342 Acc 0.859\n",
      "[ 21/25] Training Step 400 Loss 0.529 Acc 0.812\n",
      "[ 21/25] Training Step 500 Loss 0.415 Acc 0.812\n",
      "[ 21/25] Training Step 600 Loss 0.498 Acc 0.891\n",
      "[ 21/25] Training Step 700 Loss 0.484 Acc 0.781\n",
      "[ 21/25] Validate Step 015 Loss 1.791 Acc 0.589\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.310 Acc 0.891\n",
      "[ 22/25] Training Step 100 Loss 0.246 Acc 0.922\n",
      "[ 22/25] Training Step 200 Loss 0.322 Acc 0.875\n",
      "[ 22/25] Training Step 300 Loss 0.267 Acc 0.938\n",
      "[ 22/25] Training Step 400 Loss 0.271 Acc 0.891\n",
      "[ 22/25] Training Step 500 Loss 0.318 Acc 0.828\n",
      "[ 22/25] Training Step 600 Loss 0.333 Acc 0.875\n",
      "[ 22/25] Training Step 700 Loss 0.411 Acc 0.828\n",
      "[ 22/25] Validate Step 015 Loss 2.030 Acc 0.584\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.187 Acc 0.938\n",
      "[ 23/25] Training Step 100 Loss 0.147 Acc 0.953\n",
      "[ 23/25] Training Step 200 Loss 0.239 Acc 0.922\n",
      "[ 23/25] Training Step 300 Loss 0.256 Acc 0.875\n",
      "[ 23/25] Training Step 400 Loss 0.378 Acc 0.875\n",
      "[ 23/25] Training Step 500 Loss 0.101 Acc 0.969\n",
      "[ 23/25] Training Step 600 Loss 0.301 Acc 0.891\n",
      "[ 23/25] Training Step 700 Loss 0.439 Acc 0.875\n",
      "[ 23/25] Validate Step 015 Loss 2.229 Acc 0.575\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.136 Acc 0.953\n",
      "[ 24/25] Training Step 100 Loss 0.126 Acc 0.938\n",
      "[ 24/25] Training Step 200 Loss 0.121 Acc 0.953\n",
      "[ 24/25] Training Step 300 Loss 0.202 Acc 0.906\n",
      "[ 24/25] Training Step 400 Loss 0.439 Acc 0.906\n",
      "[ 24/25] Training Step 500 Loss 0.182 Acc 0.938\n",
      "[ 24/25] Training Step 600 Loss 0.190 Acc 0.922\n",
      "[ 24/25] Training Step 700 Loss 0.147 Acc 0.938\n",
      "[ 24/25] Validate Step 015 Loss 2.517 Acc 0.554\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.220 Acc 0.922\n",
      "[ 25/25] Training Step 100 Loss 0.105 Acc 0.969\n",
      "[ 25/25] Training Step 200 Loss 0.093 Acc 0.969\n",
      "[ 25/25] Training Step 300 Loss 0.190 Acc 0.938\n",
      "[ 25/25] Training Step 400 Loss 0.153 Acc 0.938\n",
      "[ 25/25] Training Step 500 Loss 0.134 Acc 0.953\n",
      "[ 25/25] Training Step 600 Loss 0.303 Acc 0.859\n",
      "[ 25/25] Training Step 700 Loss 0.273 Acc 0.906\n",
      "[ 25/25] Validate Step 015 Loss 2.354 Acc 0.563\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 2.431 Acc 0.565\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3 ModuleList API\n",
    "In this part, you have to complete the implentation of CNN with ModuleList API and Module API.\n",
    "The network should have the following architectures.\n",
    "1. A convolution layer with 16 3\\*3 filters, with stride 2\n",
    "2. ReLU\n",
    "3. A convolution layer with 32 3\\*3 filters, with stride 2\n",
    "4. ReLU\n",
    "5. Flatten\n",
    "6. A fully-connected layer produce tensor to 200 \n",
    "7. ReLU\n",
    "8. A fully-connected layer produce score to 10 (classes)\n",
    "![](./resource/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"338pt\" height=\"537pt\"\n",
       " viewBox=\"0.00 0.00 338.00 537.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 533)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-533 334,-533 334,4 -4,4\"/>\n",
       "<!-- 140472681210824 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140472681210824</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"284.5,-21 199.5,-21 199.5,0 284.5,0 284.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140471981466176 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140471981466176</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"238,-78 144,-78 144,-57 238,-57 238,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981466176&#45;&gt;140472681210824 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140471981466176&#45;&gt;140472681210824</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M200.5927,-56.7787C207.6449,-48.8969 217.3997,-37.9944 225.6699,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.3907,-30.9594 232.4503,-21.1732 223.174,-26.2918 228.3907,-30.9594\"/>\n",
       "</g>\n",
       "<!-- 140471981205768 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140471981205768</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"233.5,-141.5 148.5,-141.5 148.5,-120.5 233.5,-120.5 233.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140471981205768&#45;&gt;140471981466176 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140471981205768&#45;&gt;140471981466176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191,-120.2281C191,-111.5091 191,-98.9699 191,-88.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.5001,-88.1128 191,-78.1128 187.5001,-88.1129 194.5001,-88.1128\"/>\n",
       "</g>\n",
       "<!-- 140471981205880 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140471981205880</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"192.5,-205 79.5,-205 79.5,-184 192.5,-184 192.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140471981205880&#45;&gt;140471981205768 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140471981205880&#45;&gt;140471981205768</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.33,-183.7281C153.4383,-174.3667 165.3611,-160.6012 174.9914,-149.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"177.9063,-151.4632 181.8078,-141.6128 172.6151,-146.8802 177.9063,-151.4632\"/>\n",
       "</g>\n",
       "<!-- 140471981206048 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140471981206048</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"183,-268.5 89,-268.5 89,-247.5 183,-247.5 183,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981206048&#45;&gt;140471981205880 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140471981206048&#45;&gt;140471981205880</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136,-247.2281C136,-238.5091 136,-225.9699 136,-215.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.5001,-215.1128 136,-205.1128 132.5001,-215.1129 139.5001,-215.1128\"/>\n",
       "</g>\n",
       "<!-- 140471981206160 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140471981206160</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"217,-332 55,-332 55,-311 217,-311 217,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140471981206160&#45;&gt;140471981206048 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140471981206160&#45;&gt;140471981206048</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136,-310.7281C136,-302.0091 136,-289.4699 136,-278.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.5001,-278.6128 136,-268.6128 132.5001,-278.6129 139.5001,-278.6128\"/>\n",
       "</g>\n",
       "<!-- 140471981206272 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140471981206272</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-395.5 34,-395.5 34,-374.5 128,-374.5 128,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981206272&#45;&gt;140471981206160 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140471981206272&#45;&gt;140471981206160</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.33,-374.2281C98.4383,-364.8667 110.3611,-351.1012 119.9914,-339.9826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.9063,-341.9632 126.8078,-332.1128 117.6151,-337.3802 122.9063,-341.9632\"/>\n",
       "</g>\n",
       "<!-- 140471981206440 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140471981206440</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-459 0,-459 0,-438 162,-438 162,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140471981206440&#45;&gt;140471981206272 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140471981206440&#45;&gt;140471981206272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-437.7281C81,-429.0091 81,-416.4699 81,-405.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-405.6128 81,-395.6128 77.5001,-405.6129 84.5001,-405.6128\"/>\n",
       "</g>\n",
       "<!-- 140471981206552 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140471981206552</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"125.5,-529 36.5,-529 36.5,-495 125.5,-495 125.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">convs.0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140471981206552&#45;&gt;140471981206440 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140471981206552&#45;&gt;140471981206440</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-494.9832C81,-487.1157 81,-477.6973 81,-469.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-469.3686 81,-459.3687 77.5001,-469.3687 84.5001,-469.3686\"/>\n",
       "</g>\n",
       "<!-- 140471981206328 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140471981206328</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"235.5,-402 146.5,-402 146.5,-368 235.5,-368 235.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">convs.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140471981206328&#45;&gt;140471981206160 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140471981206328&#45;&gt;140471981206160</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M176.261,-367.9832C168.8341,-359.4085 159.8116,-348.9916 152.1918,-340.1942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.6065,-337.6361 145.4138,-332.3687 149.3153,-342.219 154.6065,-337.6361\"/>\n",
       "</g>\n",
       "<!-- 140471981205936 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140471981205936</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"283.5,-205 210.5,-205 210.5,-184 283.5,-184 283.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140471981205936&#45;&gt;140471981205768 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140471981205936&#45;&gt;140471981205768</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M237.5004,-183.7281C229.1637,-174.2749 216.8666,-160.3309 207.0119,-149.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.5987,-146.7979 200.3593,-141.6128 204.3486,-151.428 209.5987,-146.7979\"/>\n",
       "</g>\n",
       "<!-- 140471981206104 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140471981206104</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"284.5,-275 209.5,-275 209.5,-241 284.5,-241 284.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fcs.0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (200, 1568)</text>\n",
       "</g>\n",
       "<!-- 140471981206104&#45;&gt;140471981205936 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140471981206104&#45;&gt;140471981205936</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247,-240.9832C247,-233.1157 247,-223.6973 247,-215.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"250.5001,-215.3686 247,-205.3687 243.5001,-215.3687 250.5001,-215.3686\"/>\n",
       "</g>\n",
       "<!-- 140471981467128 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140471981467128</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"329.5,-78 256.5,-78 256.5,-57 329.5,-57 329.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"293\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140471981467128&#45;&gt;140472681210824 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140471981467128&#45;&gt;140472681210824</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M283.4073,-56.7787C276.3551,-48.8969 266.6003,-37.9944 258.3301,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.826,-26.2918 251.5497,-21.1732 255.6093,-30.9594 260.826,-26.2918\"/>\n",
       "</g>\n",
       "<!-- 140471981205824 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140471981205824</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"330,-148 256,-148 256,-114 330,-114 330,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"293\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fcs.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"293\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 200)</text>\n",
       "</g>\n",
       "<!-- 140471981205824&#45;&gt;140471981467128 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140471981205824&#45;&gt;140471981467128</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M293,-113.9832C293,-106.1157 293,-96.6973 293,-88.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-88.3686 293,-78.3687 289.5001,-88.3687 296.5001,-88.3686\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc25803d898>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs, self.fcs = nn.ModuleList(), nn.ModuleList()\n",
    "        ###############################################################################\n",
    "        #       TODO : Set up the layer that you need to construct the model          #\n",
    "        ###############################################################################\n",
    "        \n",
    "        self.convs.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0))\n",
    "        self.convs.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0))\n",
    "        self.fcs.append(nn.Linear(1568, 200, bias=0))\n",
    "        self.fcs.append(nn.Linear(200, 10, bias=0))\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ############################################################################### \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        ###############################################################################\n",
    "        #            TODO : Implement the forward function. You should use            #\n",
    "        #                   the layers you defined in __init__ and specify the        #\n",
    "        #                   connectivity of those layers in forward()                 #\n",
    "        ###############################################################################          \n",
    "\n",
    "        for i in range(2):\n",
    "            x = F.relu(self.convs[i](x))\n",
    "        \n",
    "        x = flatten(x)\n",
    "        x = F.relu(self.fcs[0](x))\n",
    "        out = self.fcs[1](x)\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################             \n",
    "        return out\n",
    "    \n",
    "model = ML()\n",
    "x = torch.zeros((BATCH_SIZE, 3, 32, 32))\n",
    "make_dot(model(x), params=dict(model.named_parameters())) # You can check if the picture is the same \n",
    "                                                          # as previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Train the model and check the accuracy of training dataset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.300 Acc 0.156\n",
      "[  1/25] Training Step 100 Loss 2.196 Acc 0.141\n",
      "[  1/25] Training Step 200 Loss 2.220 Acc 0.141\n",
      "[  1/25] Training Step 300 Loss 2.042 Acc 0.297\n",
      "[  1/25] Training Step 400 Loss 2.041 Acc 0.266\n",
      "[  1/25] Training Step 500 Loss 1.878 Acc 0.328\n",
      "[  1/25] Training Step 600 Loss 1.869 Acc 0.344\n",
      "[  1/25] Training Step 700 Loss 1.876 Acc 0.328\n",
      "[  1/25] Validate Step 015 Loss 1.843 Acc 0.330\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 1.868 Acc 0.297\n",
      "[  2/25] Training Step 100 Loss 1.778 Acc 0.469\n",
      "[  2/25] Training Step 200 Loss 1.818 Acc 0.359\n",
      "[  2/25] Training Step 300 Loss 1.659 Acc 0.453\n",
      "[  2/25] Training Step 400 Loss 1.446 Acc 0.422\n",
      "[  2/25] Training Step 500 Loss 1.641 Acc 0.406\n",
      "[  2/25] Training Step 600 Loss 1.384 Acc 0.516\n",
      "[  2/25] Training Step 700 Loss 1.758 Acc 0.359\n",
      "[  2/25] Validate Step 015 Loss 1.665 Acc 0.410\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.798 Acc 0.297\n",
      "[  3/25] Training Step 100 Loss 1.652 Acc 0.453\n",
      "[  3/25] Training Step 200 Loss 1.497 Acc 0.438\n",
      "[  3/25] Training Step 300 Loss 1.624 Acc 0.438\n",
      "[  3/25] Training Step 400 Loss 1.965 Acc 0.312\n",
      "[  3/25] Training Step 500 Loss 1.508 Acc 0.406\n",
      "[  3/25] Training Step 600 Loss 1.657 Acc 0.359\n",
      "[  3/25] Training Step 700 Loss 1.311 Acc 0.547\n",
      "[  3/25] Validate Step 015 Loss 1.544 Acc 0.459\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.313 Acc 0.562\n",
      "[  4/25] Training Step 100 Loss 1.586 Acc 0.438\n",
      "[  4/25] Training Step 200 Loss 1.705 Acc 0.359\n",
      "[  4/25] Training Step 300 Loss 1.472 Acc 0.531\n",
      "[  4/25] Training Step 400 Loss 1.434 Acc 0.500\n",
      "[  4/25] Training Step 500 Loss 1.463 Acc 0.422\n",
      "[  4/25] Training Step 600 Loss 1.353 Acc 0.547\n",
      "[  4/25] Training Step 700 Loss 1.413 Acc 0.516\n",
      "[  4/25] Validate Step 015 Loss 1.450 Acc 0.486\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.691 Acc 0.391\n",
      "[  5/25] Training Step 100 Loss 1.403 Acc 0.453\n",
      "[  5/25] Training Step 200 Loss 1.284 Acc 0.531\n",
      "[  5/25] Training Step 300 Loss 1.339 Acc 0.531\n",
      "[  5/25] Training Step 400 Loss 1.377 Acc 0.547\n",
      "[  5/25] Training Step 500 Loss 1.222 Acc 0.562\n",
      "[  5/25] Training Step 600 Loss 1.455 Acc 0.516\n",
      "[  5/25] Training Step 700 Loss 1.234 Acc 0.531\n",
      "[  5/25] Validate Step 015 Loss 1.412 Acc 0.525\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.397 Acc 0.547\n",
      "[  6/25] Training Step 100 Loss 1.247 Acc 0.500\n",
      "[  6/25] Training Step 200 Loss 1.426 Acc 0.406\n",
      "[  6/25] Training Step 300 Loss 1.283 Acc 0.625\n",
      "[  6/25] Training Step 400 Loss 1.175 Acc 0.594\n",
      "[  6/25] Training Step 500 Loss 1.163 Acc 0.578\n",
      "[  6/25] Training Step 600 Loss 1.281 Acc 0.562\n",
      "[  6/25] Training Step 700 Loss 1.150 Acc 0.641\n",
      "[  6/25] Validate Step 015 Loss 1.330 Acc 0.544\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.222 Acc 0.594\n",
      "[  7/25] Training Step 100 Loss 1.107 Acc 0.625\n",
      "[  7/25] Training Step 200 Loss 1.428 Acc 0.438\n",
      "[  7/25] Training Step 300 Loss 1.148 Acc 0.516\n",
      "[  7/25] Training Step 400 Loss 1.246 Acc 0.578\n",
      "[  7/25] Training Step 500 Loss 1.199 Acc 0.547\n",
      "[  7/25] Training Step 600 Loss 1.310 Acc 0.500\n",
      "[  7/25] Training Step 700 Loss 1.325 Acc 0.562\n",
      "[  7/25] Validate Step 015 Loss 1.274 Acc 0.559\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 1.366 Acc 0.641\n",
      "[  8/25] Training Step 100 Loss 1.159 Acc 0.547\n",
      "[  8/25] Training Step 200 Loss 1.125 Acc 0.562\n",
      "[  8/25] Training Step 300 Loss 1.023 Acc 0.641\n",
      "[  8/25] Training Step 400 Loss 1.364 Acc 0.484\n",
      "[  8/25] Training Step 500 Loss 1.358 Acc 0.578\n",
      "[  8/25] Training Step 600 Loss 1.383 Acc 0.531\n",
      "[  8/25] Training Step 700 Loss 1.163 Acc 0.578\n",
      "[  8/25] Validate Step 015 Loss 1.234 Acc 0.554\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 1.356 Acc 0.516\n",
      "[  9/25] Training Step 100 Loss 1.159 Acc 0.578\n",
      "[  9/25] Training Step 200 Loss 1.263 Acc 0.531\n",
      "[  9/25] Training Step 300 Loss 1.188 Acc 0.547\n",
      "[  9/25] Training Step 400 Loss 1.035 Acc 0.594\n",
      "[  9/25] Training Step 500 Loss 1.337 Acc 0.578\n",
      "[  9/25] Training Step 600 Loss 1.143 Acc 0.594\n",
      "[  9/25] Training Step 700 Loss 0.879 Acc 0.719\n",
      "[  9/25] Validate Step 015 Loss 1.199 Acc 0.573\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 1.096 Acc 0.656\n",
      "[ 10/25] Training Step 100 Loss 1.042 Acc 0.625\n",
      "[ 10/25] Training Step 200 Loss 1.002 Acc 0.641\n",
      "[ 10/25] Training Step 300 Loss 0.982 Acc 0.719\n",
      "[ 10/25] Training Step 400 Loss 1.037 Acc 0.609\n",
      "[ 10/25] Training Step 500 Loss 1.209 Acc 0.734\n",
      "[ 10/25] Training Step 600 Loss 1.208 Acc 0.578\n",
      "[ 10/25] Training Step 700 Loss 1.048 Acc 0.625\n",
      "[ 10/25] Validate Step 015 Loss 1.206 Acc 0.578\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 1.211 Acc 0.625\n",
      "[ 11/25] Training Step 100 Loss 1.124 Acc 0.688\n",
      "[ 11/25] Training Step 200 Loss 1.142 Acc 0.562\n",
      "[ 11/25] Training Step 300 Loss 0.944 Acc 0.672\n",
      "[ 11/25] Training Step 400 Loss 1.036 Acc 0.672\n",
      "[ 11/25] Training Step 500 Loss 1.124 Acc 0.641\n",
      "[ 11/25] Training Step 600 Loss 1.012 Acc 0.641\n",
      "[ 11/25] Training Step 700 Loss 0.942 Acc 0.578\n",
      "[ 11/25] Validate Step 015 Loss 1.168 Acc 0.594\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 0.880 Acc 0.734\n",
      "[ 12/25] Training Step 100 Loss 1.267 Acc 0.531\n",
      "[ 12/25] Training Step 200 Loss 1.214 Acc 0.562\n",
      "[ 12/25] Training Step 300 Loss 0.943 Acc 0.641\n",
      "[ 12/25] Training Step 400 Loss 1.208 Acc 0.547\n",
      "[ 12/25] Training Step 500 Loss 0.923 Acc 0.656\n",
      "[ 12/25] Training Step 600 Loss 1.192 Acc 0.531\n",
      "[ 12/25] Training Step 700 Loss 1.170 Acc 0.500\n",
      "[ 12/25] Validate Step 015 Loss 1.173 Acc 0.585\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.983 Acc 0.688\n",
      "[ 13/25] Training Step 100 Loss 1.124 Acc 0.641\n",
      "[ 13/25] Training Step 200 Loss 1.052 Acc 0.656\n",
      "[ 13/25] Training Step 300 Loss 1.179 Acc 0.625\n",
      "[ 13/25] Training Step 400 Loss 0.815 Acc 0.703\n",
      "[ 13/25] Training Step 500 Loss 1.007 Acc 0.688\n",
      "[ 13/25] Training Step 600 Loss 1.117 Acc 0.656\n",
      "[ 13/25] Training Step 700 Loss 1.011 Acc 0.703\n",
      "[ 13/25] Validate Step 015 Loss 1.147 Acc 0.580\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 1.168 Acc 0.578\n",
      "[ 14/25] Training Step 100 Loss 1.032 Acc 0.625\n",
      "[ 14/25] Training Step 200 Loss 0.852 Acc 0.719\n",
      "[ 14/25] Training Step 300 Loss 0.920 Acc 0.719\n",
      "[ 14/25] Training Step 400 Loss 1.116 Acc 0.578\n",
      "[ 14/25] Training Step 500 Loss 0.849 Acc 0.688\n",
      "[ 14/25] Training Step 600 Loss 0.887 Acc 0.703\n",
      "[ 14/25] Training Step 700 Loss 1.099 Acc 0.656\n",
      "[ 14/25] Validate Step 015 Loss 1.112 Acc 0.595\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.915 Acc 0.656\n",
      "[ 15/25] Training Step 100 Loss 0.996 Acc 0.641\n",
      "[ 15/25] Training Step 200 Loss 0.778 Acc 0.719\n",
      "[ 15/25] Training Step 300 Loss 1.026 Acc 0.625\n",
      "[ 15/25] Training Step 400 Loss 0.864 Acc 0.672\n",
      "[ 15/25] Training Step 500 Loss 0.950 Acc 0.656\n",
      "[ 15/25] Training Step 600 Loss 0.717 Acc 0.812\n",
      "[ 15/25] Training Step 700 Loss 0.811 Acc 0.719\n",
      "[ 15/25] Validate Step 015 Loss 1.127 Acc 0.609\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.753 Acc 0.750\n",
      "[ 16/25] Training Step 100 Loss 1.027 Acc 0.641\n",
      "[ 16/25] Training Step 200 Loss 1.120 Acc 0.594\n",
      "[ 16/25] Training Step 300 Loss 1.010 Acc 0.656\n",
      "[ 16/25] Training Step 400 Loss 0.806 Acc 0.625\n",
      "[ 16/25] Training Step 500 Loss 0.989 Acc 0.703\n",
      "[ 16/25] Training Step 600 Loss 0.823 Acc 0.703\n",
      "[ 16/25] Training Step 700 Loss 0.895 Acc 0.766\n",
      "[ 16/25] Validate Step 015 Loss 1.122 Acc 0.611\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.750 Acc 0.750\n",
      "[ 17/25] Training Step 100 Loss 0.738 Acc 0.781\n",
      "[ 17/25] Training Step 200 Loss 0.832 Acc 0.703\n",
      "[ 17/25] Training Step 300 Loss 0.769 Acc 0.734\n",
      "[ 17/25] Training Step 400 Loss 0.845 Acc 0.766\n",
      "[ 17/25] Training Step 500 Loss 0.767 Acc 0.750\n",
      "[ 17/25] Training Step 600 Loss 0.842 Acc 0.656\n",
      "[ 17/25] Training Step 700 Loss 0.706 Acc 0.797\n",
      "[ 17/25] Validate Step 015 Loss 1.144 Acc 0.613\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 0.818 Acc 0.719\n",
      "[ 18/25] Training Step 100 Loss 0.712 Acc 0.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.774 Acc 0.797\n",
      "[ 18/25] Training Step 300 Loss 0.852 Acc 0.641\n",
      "[ 18/25] Training Step 400 Loss 0.878 Acc 0.672\n",
      "[ 18/25] Training Step 500 Loss 0.845 Acc 0.656\n",
      "[ 18/25] Training Step 600 Loss 0.892 Acc 0.656\n",
      "[ 18/25] Training Step 700 Loss 0.932 Acc 0.625\n",
      "[ 18/25] Validate Step 015 Loss 1.155 Acc 0.620\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.594 Acc 0.750\n",
      "[ 19/25] Training Step 100 Loss 0.769 Acc 0.703\n",
      "[ 19/25] Training Step 200 Loss 0.831 Acc 0.734\n",
      "[ 19/25] Training Step 300 Loss 0.693 Acc 0.797\n",
      "[ 19/25] Training Step 400 Loss 0.985 Acc 0.641\n",
      "[ 19/25] Training Step 500 Loss 0.851 Acc 0.719\n",
      "[ 19/25] Training Step 600 Loss 0.699 Acc 0.750\n",
      "[ 19/25] Training Step 700 Loss 0.814 Acc 0.656\n",
      "[ 19/25] Validate Step 015 Loss 1.145 Acc 0.616\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.658 Acc 0.812\n",
      "[ 20/25] Training Step 100 Loss 0.618 Acc 0.781\n",
      "[ 20/25] Training Step 200 Loss 0.575 Acc 0.766\n",
      "[ 20/25] Training Step 300 Loss 0.511 Acc 0.828\n",
      "[ 20/25] Training Step 400 Loss 0.704 Acc 0.734\n",
      "[ 20/25] Training Step 500 Loss 0.763 Acc 0.734\n",
      "[ 20/25] Training Step 600 Loss 0.726 Acc 0.781\n",
      "[ 20/25] Training Step 700 Loss 0.869 Acc 0.688\n",
      "[ 20/25] Validate Step 015 Loss 1.160 Acc 0.605\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.565 Acc 0.797\n",
      "[ 21/25] Training Step 100 Loss 0.704 Acc 0.781\n",
      "[ 21/25] Training Step 200 Loss 0.642 Acc 0.797\n",
      "[ 21/25] Training Step 300 Loss 0.493 Acc 0.875\n",
      "[ 21/25] Training Step 400 Loss 0.768 Acc 0.781\n",
      "[ 21/25] Training Step 500 Loss 0.817 Acc 0.688\n",
      "[ 21/25] Training Step 600 Loss 0.859 Acc 0.594\n",
      "[ 21/25] Training Step 700 Loss 0.742 Acc 0.750\n",
      "[ 21/25] Validate Step 015 Loss 1.213 Acc 0.618\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.603 Acc 0.750\n",
      "[ 22/25] Training Step 100 Loss 0.624 Acc 0.828\n",
      "[ 22/25] Training Step 200 Loss 0.827 Acc 0.719\n",
      "[ 22/25] Training Step 300 Loss 0.475 Acc 0.812\n",
      "[ 22/25] Training Step 400 Loss 0.760 Acc 0.734\n",
      "[ 22/25] Training Step 500 Loss 0.737 Acc 0.797\n",
      "[ 22/25] Training Step 600 Loss 0.586 Acc 0.797\n",
      "[ 22/25] Training Step 700 Loss 0.629 Acc 0.797\n",
      "[ 22/25] Validate Step 015 Loss 1.272 Acc 0.608\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.624 Acc 0.797\n",
      "[ 23/25] Training Step 100 Loss 0.543 Acc 0.844\n",
      "[ 23/25] Training Step 200 Loss 0.496 Acc 0.797\n",
      "[ 23/25] Training Step 300 Loss 0.642 Acc 0.781\n",
      "[ 23/25] Training Step 400 Loss 0.701 Acc 0.797\n",
      "[ 23/25] Training Step 500 Loss 0.561 Acc 0.766\n",
      "[ 23/25] Training Step 600 Loss 0.466 Acc 0.828\n",
      "[ 23/25] Training Step 700 Loss 0.531 Acc 0.828\n",
      "[ 23/25] Validate Step 015 Loss 1.272 Acc 0.606\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.659 Acc 0.750\n",
      "[ 24/25] Training Step 100 Loss 0.469 Acc 0.844\n",
      "[ 24/25] Training Step 200 Loss 0.391 Acc 0.844\n",
      "[ 24/25] Training Step 300 Loss 0.336 Acc 0.844\n",
      "[ 24/25] Training Step 400 Loss 0.608 Acc 0.812\n",
      "[ 24/25] Training Step 500 Loss 0.524 Acc 0.844\n",
      "[ 24/25] Training Step 600 Loss 0.451 Acc 0.828\n",
      "[ 24/25] Training Step 700 Loss 0.537 Acc 0.812\n",
      "[ 24/25] Validate Step 015 Loss 1.271 Acc 0.626\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.360 Acc 0.859\n",
      "[ 25/25] Training Step 100 Loss 0.255 Acc 0.938\n",
      "[ 25/25] Training Step 200 Loss 0.539 Acc 0.828\n",
      "[ 25/25] Training Step 300 Loss 0.393 Acc 0.844\n",
      "[ 25/25] Training Step 400 Loss 0.358 Acc 0.875\n",
      "[ 25/25] Training Step 500 Loss 0.781 Acc 0.812\n",
      "[ 25/25] Training Step 600 Loss 0.743 Acc 0.812\n",
      "[ 25/25] Training Step 700 Loss 0.733 Acc 0.703\n",
      "[ 25/25] Validate Step 015 Loss 1.371 Acc 0.614\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 1.401 Acc 0.595\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4 Sequential\n",
    "In this part, you have to complete the implentation of CNN with Sequential API.\n",
    "The network should have the following architectures.\n",
    "1. A convolution layer with 16 3\\*3 filters, with stride 2\n",
    "2. ReLU\n",
    "3. A convolution layer with 32 3\\*3 filters, with stride 2\n",
    "4. ReLU\n",
    "5. Flatten\n",
    "6. A fully-connected layer produce tensor to 200 \n",
    "7. ReLU\n",
    "8. A fully-connected layer produce score to 10 (classes)\n",
    "![](./resource/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"537pt\"\n",
       " viewBox=\"0.00 0.00 335.50 537.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 533)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-533 331.5,-533 331.5,4 -4,4\"/>\n",
       "<!-- 140472675899320 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140472675899320</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"282.5,-21 197.5,-21 197.5,0 282.5,0 282.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140472675898200 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140472675898200</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"236,-78 142,-78 142,-57 236,-57 236,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140472675898200&#45;&gt;140472675899320 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140472675898200&#45;&gt;140472675899320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.5927,-56.7787C205.6449,-48.8969 215.3997,-37.9944 223.6699,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.3907,-30.9594 230.4503,-21.1732 221.174,-26.2918 226.3907,-30.9594\"/>\n",
       "</g>\n",
       "<!-- 140472675898704 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140472675898704</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231.5,-141.5 146.5,-141.5 146.5,-120.5 231.5,-120.5 231.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140472675898704&#45;&gt;140472675898200 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140472675898704&#45;&gt;140472675898200</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189,-120.2281C189,-111.5091 189,-98.9699 189,-88.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.5001,-88.1128 189,-78.1128 185.5001,-88.1129 192.5001,-88.1128\"/>\n",
       "</g>\n",
       "<!-- 140472675901392 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140472675901392</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"190.5,-205 77.5,-205 77.5,-184 190.5,-184 190.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140472675901392&#45;&gt;140472675898704 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140472675901392&#45;&gt;140472675898704</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.33,-183.7281C151.4383,-174.3667 163.3611,-160.6012 172.9914,-149.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"175.9063,-151.4632 179.8078,-141.6128 170.6151,-146.8802 175.9063,-151.4632\"/>\n",
       "</g>\n",
       "<!-- 140472675901056 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140472675901056</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"181,-268.5 87,-268.5 87,-247.5 181,-247.5 181,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140472675901056&#45;&gt;140472675901392 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140472675901056&#45;&gt;140472675901392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-247.2281C134,-238.5091 134,-225.9699 134,-215.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-215.1128 134,-205.1128 130.5001,-215.1129 137.5001,-215.1128\"/>\n",
       "</g>\n",
       "<!-- 140472675901224 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140472675901224</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"215,-332 53,-332 53,-311 215,-311 215,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140472675901224&#45;&gt;140472675901056 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140472675901224&#45;&gt;140472675901056</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-310.7281C134,-302.0091 134,-289.4699 134,-278.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-278.6128 134,-268.6128 130.5001,-278.6129 137.5001,-278.6128\"/>\n",
       "</g>\n",
       "<!-- 140472675901000 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140472675901000</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-395.5 34,-395.5 34,-374.5 128,-374.5 128,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140472675901000&#45;&gt;140472675901224 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140472675901000&#45;&gt;140472675901224</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.9907,-374.2281C97.8042,-364.8667 109.2935,-351.1012 118.5736,-339.9826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.4213,-342.0328 125.1421,-332.1128 116.0472,-337.5474 121.4213,-342.0328\"/>\n",
       "</g>\n",
       "<!-- 140472676159616 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140472676159616</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-459 0,-459 0,-438 162,-438 162,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140472676159616&#45;&gt;140472675901000 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140472676159616&#45;&gt;140472675901000</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-437.7281C81,-429.0091 81,-416.4699 81,-405.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-405.6128 81,-395.6128 77.5001,-405.6129 84.5001,-405.6128\"/>\n",
       "</g>\n",
       "<!-- 140472676162472 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140472676162472</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"121.5,-529 40.5,-529 40.5,-495 121.5,-495 121.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140472676162472&#45;&gt;140472676159616 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140472676162472&#45;&gt;140472676159616</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-494.9832C81,-487.1157 81,-477.6973 81,-469.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-469.3686 81,-459.3687 77.5001,-469.3687 84.5001,-469.3686\"/>\n",
       "</g>\n",
       "<!-- 140474679405984 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140474679405984</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"227.5,-402 146.5,-402 146.5,-368 227.5,-368 227.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140474679405984&#45;&gt;140472675901224 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140474679405984&#45;&gt;140472675901224</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.797,-367.9832C165.6401,-359.4085 156.9458,-348.9916 149.603,-340.1942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.1664,-337.8032 143.0715,-332.3687 146.7923,-342.2887 152.1664,-337.8032\"/>\n",
       "</g>\n",
       "<!-- 140472675901336 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140472675901336</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"281.5,-205 208.5,-205 208.5,-184 281.5,-184 281.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140472675901336&#45;&gt;140472675898704 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140472675901336&#45;&gt;140472675898704</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.5004,-183.7281C227.1637,-174.2749 214.8666,-160.3309 205.0119,-149.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.5987,-146.7979 198.3593,-141.6128 202.3486,-151.428 207.5987,-146.7979\"/>\n",
       "</g>\n",
       "<!-- 140472675901280 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140472675901280</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"282.5,-275 207.5,-275 207.5,-241 282.5,-241 282.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (200, 1568)</text>\n",
       "</g>\n",
       "<!-- 140472675901280&#45;&gt;140472675901336 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140472675901280&#45;&gt;140472675901336</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245,-240.9832C245,-233.1157 245,-223.6973 245,-215.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.5001,-215.3686 245,-205.3687 241.5001,-215.3687 248.5001,-215.3686\"/>\n",
       "</g>\n",
       "<!-- 140472675899208 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140472675899208</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"327.5,-78 254.5,-78 254.5,-57 327.5,-57 327.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140472675899208&#45;&gt;140472675899320 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140472675899208&#45;&gt;140472675899320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.4073,-56.7787C274.3551,-48.8969 264.6003,-37.9944 256.3301,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.826,-26.2918 249.5497,-21.1732 253.6093,-30.9594 258.826,-26.2918\"/>\n",
       "</g>\n",
       "<!-- 140472675898312 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140472675898312</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"324.5,-148 257.5,-148 257.5,-114 324.5,-114 324.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 200)</text>\n",
       "</g>\n",
       "<!-- 140472675898312&#45;&gt;140472675899208 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140472675898312&#45;&gt;140472675899208</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291,-113.9832C291,-106.1157 291,-96.6973 291,-88.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.5001,-88.3686 291,-78.3687 287.5001,-88.3687 294.5001,-88.3686\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc257f296d8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = None\n",
    "###############################################################################\n",
    "#            TODO : Implement the Sequential API to complete the model        #\n",
    "###############################################################################          \n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('flatten', Flatten()),\n",
    "    ('fc1', nn.Linear(1568, 200, bias=0)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(200, 10, bias=0))\n",
    "    ]))\n",
    "\n",
    "###############################################################################\n",
    "#                            END TO DO                                        #\n",
    "###############################################################################  \n",
    "x = torch.zeros((BATCH_SIZE, 3, 32, 32))\n",
    "make_dot(model(x), params=dict(model.named_parameters())) # You can check if the picture is the same \n",
    "                                                          # as previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Train the model and check the accuracy of training dataset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.303 Acc 0.141\n",
      "[  1/25] Training Step 100 Loss 2.291 Acc 0.172\n",
      "[  1/25] Training Step 200 Loss 2.262 Acc 0.250\n",
      "[  1/25] Training Step 300 Loss 2.171 Acc 0.328\n",
      "[  1/25] Training Step 400 Loss 2.079 Acc 0.281\n",
      "[  1/25] Training Step 500 Loss 1.974 Acc 0.266\n",
      "[  1/25] Training Step 600 Loss 2.082 Acc 0.266\n",
      "[  1/25] Training Step 700 Loss 1.987 Acc 0.297\n",
      "[  1/25] Validate Step 015 Loss 1.898 Acc 0.342\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 1.807 Acc 0.375\n",
      "[  2/25] Training Step 100 Loss 1.864 Acc 0.328\n",
      "[  2/25] Training Step 200 Loss 1.657 Acc 0.297\n",
      "[  2/25] Training Step 300 Loss 1.783 Acc 0.359\n",
      "[  2/25] Training Step 400 Loss 1.751 Acc 0.422\n",
      "[  2/25] Training Step 500 Loss 1.750 Acc 0.375\n",
      "[  2/25] Training Step 600 Loss 1.723 Acc 0.406\n",
      "[  2/25] Training Step 700 Loss 1.709 Acc 0.312\n",
      "[  2/25] Validate Step 015 Loss 1.684 Acc 0.419\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.676 Acc 0.453\n",
      "[  3/25] Training Step 100 Loss 1.605 Acc 0.406\n",
      "[  3/25] Training Step 200 Loss 1.571 Acc 0.484\n",
      "[  3/25] Training Step 300 Loss 1.753 Acc 0.328\n",
      "[  3/25] Training Step 400 Loss 1.490 Acc 0.500\n",
      "[  3/25] Training Step 500 Loss 1.518 Acc 0.438\n",
      "[  3/25] Training Step 600 Loss 1.502 Acc 0.500\n",
      "[  3/25] Training Step 700 Loss 1.434 Acc 0.484\n",
      "[  3/25] Validate Step 015 Loss 1.520 Acc 0.463\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.594 Acc 0.469\n",
      "[  4/25] Training Step 100 Loss 1.495 Acc 0.484\n",
      "[  4/25] Training Step 200 Loss 1.448 Acc 0.469\n",
      "[  4/25] Training Step 300 Loss 1.534 Acc 0.375\n",
      "[  4/25] Training Step 400 Loss 1.315 Acc 0.547\n",
      "[  4/25] Training Step 500 Loss 1.493 Acc 0.453\n",
      "[  4/25] Training Step 600 Loss 1.344 Acc 0.469\n",
      "[  4/25] Training Step 700 Loss 1.314 Acc 0.562\n",
      "[  4/25] Validate Step 015 Loss 1.378 Acc 0.515\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.396 Acc 0.484\n",
      "[  5/25] Training Step 100 Loss 1.563 Acc 0.547\n",
      "[  5/25] Training Step 200 Loss 1.413 Acc 0.578\n",
      "[  5/25] Training Step 300 Loss 1.313 Acc 0.484\n",
      "[  5/25] Training Step 400 Loss 1.233 Acc 0.594\n",
      "[  5/25] Training Step 500 Loss 1.337 Acc 0.531\n",
      "[  5/25] Training Step 600 Loss 1.580 Acc 0.438\n",
      "[  5/25] Training Step 700 Loss 1.212 Acc 0.609\n",
      "[  5/25] Validate Step 015 Loss 1.322 Acc 0.518\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.246 Acc 0.547\n",
      "[  6/25] Training Step 100 Loss 1.335 Acc 0.469\n",
      "[  6/25] Training Step 200 Loss 1.341 Acc 0.578\n",
      "[  6/25] Training Step 300 Loss 1.296 Acc 0.547\n",
      "[  6/25] Training Step 400 Loss 1.178 Acc 0.656\n",
      "[  6/25] Training Step 500 Loss 1.289 Acc 0.484\n",
      "[  6/25] Training Step 600 Loss 1.180 Acc 0.609\n",
      "[  6/25] Training Step 700 Loss 1.140 Acc 0.578\n",
      "[  6/25] Validate Step 015 Loss 1.283 Acc 0.548\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.108 Acc 0.594\n",
      "[  7/25] Training Step 100 Loss 1.397 Acc 0.578\n",
      "[  7/25] Training Step 200 Loss 1.285 Acc 0.578\n",
      "[  7/25] Training Step 300 Loss 1.354 Acc 0.531\n",
      "[  7/25] Training Step 400 Loss 1.151 Acc 0.656\n",
      "[  7/25] Training Step 500 Loss 1.388 Acc 0.484\n",
      "[  7/25] Training Step 600 Loss 1.049 Acc 0.688\n",
      "[  7/25] Training Step 700 Loss 1.197 Acc 0.562\n",
      "[  7/25] Validate Step 015 Loss 1.244 Acc 0.570\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 1.214 Acc 0.547\n",
      "[  8/25] Training Step 100 Loss 1.151 Acc 0.625\n",
      "[  8/25] Training Step 200 Loss 1.191 Acc 0.594\n",
      "[  8/25] Training Step 300 Loss 1.621 Acc 0.438\n",
      "[  8/25] Training Step 400 Loss 0.942 Acc 0.734\n",
      "[  8/25] Training Step 500 Loss 1.195 Acc 0.594\n",
      "[  8/25] Training Step 600 Loss 1.173 Acc 0.578\n",
      "[  8/25] Training Step 700 Loss 1.130 Acc 0.562\n",
      "[  8/25] Validate Step 015 Loss 1.191 Acc 0.583\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 0.895 Acc 0.703\n",
      "[  9/25] Training Step 100 Loss 1.376 Acc 0.531\n",
      "[  9/25] Training Step 200 Loss 1.072 Acc 0.641\n",
      "[  9/25] Training Step 300 Loss 1.096 Acc 0.594\n",
      "[  9/25] Training Step 400 Loss 0.946 Acc 0.656\n",
      "[  9/25] Training Step 500 Loss 0.964 Acc 0.688\n",
      "[  9/25] Training Step 600 Loss 1.023 Acc 0.672\n",
      "[  9/25] Training Step 700 Loss 1.229 Acc 0.578\n",
      "[  9/25] Validate Step 015 Loss 1.158 Acc 0.605\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 1.113 Acc 0.578\n",
      "[ 10/25] Training Step 100 Loss 0.890 Acc 0.719\n",
      "[ 10/25] Training Step 200 Loss 1.178 Acc 0.547\n",
      "[ 10/25] Training Step 300 Loss 1.232 Acc 0.594\n",
      "[ 10/25] Training Step 400 Loss 1.087 Acc 0.641\n",
      "[ 10/25] Training Step 500 Loss 1.129 Acc 0.594\n",
      "[ 10/25] Training Step 600 Loss 1.195 Acc 0.562\n",
      "[ 10/25] Training Step 700 Loss 1.083 Acc 0.688\n",
      "[ 10/25] Validate Step 015 Loss 1.168 Acc 0.611\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 1.055 Acc 0.547\n",
      "[ 11/25] Training Step 100 Loss 1.109 Acc 0.562\n",
      "[ 11/25] Training Step 200 Loss 1.385 Acc 0.422\n",
      "[ 11/25] Training Step 300 Loss 1.201 Acc 0.594\n",
      "[ 11/25] Training Step 400 Loss 1.130 Acc 0.578\n",
      "[ 11/25] Training Step 500 Loss 0.900 Acc 0.703\n",
      "[ 11/25] Training Step 600 Loss 0.781 Acc 0.766\n",
      "[ 11/25] Training Step 700 Loss 1.237 Acc 0.562\n",
      "[ 11/25] Validate Step 015 Loss 1.113 Acc 0.622\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 0.825 Acc 0.734\n",
      "[ 12/25] Training Step 100 Loss 1.090 Acc 0.562\n",
      "[ 12/25] Training Step 200 Loss 0.953 Acc 0.766\n",
      "[ 12/25] Training Step 300 Loss 0.944 Acc 0.656\n",
      "[ 12/25] Training Step 400 Loss 0.876 Acc 0.734\n",
      "[ 12/25] Training Step 500 Loss 0.934 Acc 0.703\n",
      "[ 12/25] Training Step 600 Loss 1.054 Acc 0.609\n",
      "[ 12/25] Training Step 700 Loss 0.947 Acc 0.719\n",
      "[ 12/25] Validate Step 015 Loss 1.104 Acc 0.615\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.996 Acc 0.594\n",
      "[ 13/25] Training Step 100 Loss 0.987 Acc 0.672\n",
      "[ 13/25] Training Step 200 Loss 0.951 Acc 0.672\n",
      "[ 13/25] Training Step 300 Loss 0.811 Acc 0.750\n",
      "[ 13/25] Training Step 400 Loss 1.177 Acc 0.625\n",
      "[ 13/25] Training Step 500 Loss 0.927 Acc 0.672\n",
      "[ 13/25] Training Step 600 Loss 1.164 Acc 0.594\n",
      "[ 13/25] Training Step 700 Loss 1.123 Acc 0.641\n",
      "[ 13/25] Validate Step 015 Loss 1.085 Acc 0.609\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 0.836 Acc 0.688\n",
      "[ 14/25] Training Step 100 Loss 0.784 Acc 0.703\n",
      "[ 14/25] Training Step 200 Loss 0.921 Acc 0.672\n",
      "[ 14/25] Training Step 300 Loss 0.950 Acc 0.719\n",
      "[ 14/25] Training Step 400 Loss 0.865 Acc 0.672\n",
      "[ 14/25] Training Step 500 Loss 1.012 Acc 0.719\n",
      "[ 14/25] Training Step 600 Loss 0.904 Acc 0.719\n",
      "[ 14/25] Training Step 700 Loss 0.909 Acc 0.656\n",
      "[ 14/25] Validate Step 015 Loss 1.061 Acc 0.632\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.948 Acc 0.703\n",
      "[ 15/25] Training Step 100 Loss 0.780 Acc 0.719\n",
      "[ 15/25] Training Step 200 Loss 0.853 Acc 0.688\n",
      "[ 15/25] Training Step 300 Loss 1.075 Acc 0.672\n",
      "[ 15/25] Training Step 400 Loss 0.982 Acc 0.719\n",
      "[ 15/25] Training Step 500 Loss 0.930 Acc 0.641\n",
      "[ 15/25] Training Step 600 Loss 1.055 Acc 0.625\n",
      "[ 15/25] Training Step 700 Loss 0.935 Acc 0.688\n",
      "[ 15/25] Validate Step 015 Loss 1.062 Acc 0.627\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.963 Acc 0.703\n",
      "[ 16/25] Training Step 100 Loss 0.723 Acc 0.766\n",
      "[ 16/25] Training Step 200 Loss 0.775 Acc 0.734\n",
      "[ 16/25] Training Step 300 Loss 0.753 Acc 0.734\n",
      "[ 16/25] Training Step 400 Loss 1.060 Acc 0.562\n",
      "[ 16/25] Training Step 500 Loss 0.745 Acc 0.719\n",
      "[ 16/25] Training Step 600 Loss 0.803 Acc 0.766\n",
      "[ 16/25] Training Step 700 Loss 0.948 Acc 0.672\n",
      "[ 16/25] Validate Step 015 Loss 1.060 Acc 0.642\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.647 Acc 0.797\n",
      "[ 17/25] Training Step 100 Loss 0.793 Acc 0.750\n",
      "[ 17/25] Training Step 200 Loss 0.740 Acc 0.734\n",
      "[ 17/25] Training Step 300 Loss 0.806 Acc 0.688\n",
      "[ 17/25] Training Step 400 Loss 0.759 Acc 0.719\n",
      "[ 17/25] Training Step 500 Loss 0.772 Acc 0.703\n",
      "[ 17/25] Training Step 600 Loss 1.077 Acc 0.594\n",
      "[ 17/25] Training Step 700 Loss 0.714 Acc 0.688\n",
      "[ 17/25] Validate Step 015 Loss 1.074 Acc 0.637\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 0.547 Acc 0.828\n",
      "[ 18/25] Training Step 100 Loss 0.868 Acc 0.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.568 Acc 0.781\n",
      "[ 18/25] Training Step 300 Loss 1.018 Acc 0.766\n",
      "[ 18/25] Training Step 400 Loss 0.865 Acc 0.672\n",
      "[ 18/25] Training Step 500 Loss 0.672 Acc 0.750\n",
      "[ 18/25] Training Step 600 Loss 0.871 Acc 0.688\n",
      "[ 18/25] Training Step 700 Loss 0.780 Acc 0.734\n",
      "[ 18/25] Validate Step 015 Loss 1.116 Acc 0.643\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.626 Acc 0.781\n",
      "[ 19/25] Training Step 100 Loss 0.519 Acc 0.859\n",
      "[ 19/25] Training Step 200 Loss 0.750 Acc 0.719\n",
      "[ 19/25] Training Step 300 Loss 0.583 Acc 0.828\n",
      "[ 19/25] Training Step 400 Loss 0.716 Acc 0.750\n",
      "[ 19/25] Training Step 500 Loss 0.858 Acc 0.672\n",
      "[ 19/25] Training Step 600 Loss 0.874 Acc 0.734\n",
      "[ 19/25] Training Step 700 Loss 0.739 Acc 0.734\n",
      "[ 19/25] Validate Step 015 Loss 1.096 Acc 0.649\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.632 Acc 0.781\n",
      "[ 20/25] Training Step 100 Loss 0.577 Acc 0.781\n",
      "[ 20/25] Training Step 200 Loss 0.593 Acc 0.750\n",
      "[ 20/25] Training Step 300 Loss 0.894 Acc 0.766\n",
      "[ 20/25] Training Step 400 Loss 0.531 Acc 0.812\n",
      "[ 20/25] Training Step 500 Loss 0.675 Acc 0.766\n",
      "[ 20/25] Training Step 600 Loss 0.562 Acc 0.844\n",
      "[ 20/25] Training Step 700 Loss 0.744 Acc 0.719\n",
      "[ 20/25] Validate Step 015 Loss 1.102 Acc 0.659\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.615 Acc 0.734\n",
      "[ 21/25] Training Step 100 Loss 0.624 Acc 0.797\n",
      "[ 21/25] Training Step 200 Loss 0.550 Acc 0.766\n",
      "[ 21/25] Training Step 300 Loss 0.491 Acc 0.812\n",
      "[ 21/25] Training Step 400 Loss 0.696 Acc 0.828\n",
      "[ 21/25] Training Step 500 Loss 0.776 Acc 0.781\n",
      "[ 21/25] Training Step 600 Loss 0.674 Acc 0.766\n",
      "[ 21/25] Training Step 700 Loss 0.732 Acc 0.719\n",
      "[ 21/25] Validate Step 015 Loss 1.121 Acc 0.634\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.492 Acc 0.844\n",
      "[ 22/25] Training Step 100 Loss 0.646 Acc 0.812\n",
      "[ 22/25] Training Step 200 Loss 0.513 Acc 0.828\n",
      "[ 22/25] Training Step 300 Loss 0.640 Acc 0.734\n",
      "[ 22/25] Training Step 400 Loss 0.839 Acc 0.734\n",
      "[ 22/25] Training Step 500 Loss 0.553 Acc 0.812\n",
      "[ 22/25] Training Step 600 Loss 0.515 Acc 0.844\n",
      "[ 22/25] Training Step 700 Loss 0.531 Acc 0.828\n",
      "[ 22/25] Validate Step 015 Loss 1.129 Acc 0.639\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.539 Acc 0.844\n",
      "[ 23/25] Training Step 100 Loss 0.415 Acc 0.875\n",
      "[ 23/25] Training Step 200 Loss 0.595 Acc 0.766\n",
      "[ 23/25] Training Step 300 Loss 0.546 Acc 0.844\n",
      "[ 23/25] Training Step 400 Loss 0.423 Acc 0.891\n",
      "[ 23/25] Training Step 500 Loss 0.467 Acc 0.844\n",
      "[ 23/25] Training Step 600 Loss 0.495 Acc 0.875\n",
      "[ 23/25] Training Step 700 Loss 0.540 Acc 0.859\n",
      "[ 23/25] Validate Step 015 Loss 1.182 Acc 0.648\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.613 Acc 0.750\n",
      "[ 24/25] Training Step 100 Loss 0.488 Acc 0.906\n",
      "[ 24/25] Training Step 200 Loss 0.452 Acc 0.891\n",
      "[ 24/25] Training Step 300 Loss 0.424 Acc 0.844\n",
      "[ 24/25] Training Step 400 Loss 0.336 Acc 0.891\n",
      "[ 24/25] Training Step 500 Loss 0.434 Acc 0.828\n",
      "[ 24/25] Training Step 600 Loss 0.615 Acc 0.781\n",
      "[ 24/25] Training Step 700 Loss 0.468 Acc 0.859\n",
      "[ 24/25] Validate Step 015 Loss 1.178 Acc 0.642\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.480 Acc 0.844\n",
      "[ 25/25] Training Step 100 Loss 0.333 Acc 0.906\n",
      "[ 25/25] Training Step 200 Loss 0.420 Acc 0.859\n",
      "[ 25/25] Training Step 300 Loss 0.339 Acc 0.859\n",
      "[ 25/25] Training Step 400 Loss 0.349 Acc 0.875\n",
      "[ 25/25] Training Step 500 Loss 0.397 Acc 0.828\n",
      "[ 25/25] Training Step 600 Loss 0.326 Acc 0.859\n",
      "[ 25/25] Training Step 700 Loss 0.579 Acc 0.781\n",
      "[ 25/25] Validate Step 015 Loss 1.247 Acc 0.654\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 1.291 Acc 0.632\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 CIFAR-10 open-ended challenge\n",
    "In this section, you can experiment with whatever ConvNet architecture you'd like on CIFAR-10\n",
    "### Baseline : 65% on Testing data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/15] Training Step 000 Loss 2.321 Acc 0.078\n",
      "[  1/15] Training Step 100 Loss 1.895 Acc 0.266\n",
      "[  1/15] Training Step 200 Loss 1.714 Acc 0.312\n",
      "[  1/15] Training Step 300 Loss 1.400 Acc 0.391\n",
      "[  1/15] Training Step 400 Loss 1.529 Acc 0.516\n",
      "[  1/15] Training Step 500 Loss 1.296 Acc 0.547\n",
      "[  1/15] Training Step 600 Loss 1.140 Acc 0.641\n",
      "[  1/15] Training Step 700 Loss 1.330 Acc 0.531\n",
      "[  1/15] Validate Step 015 Loss 1.212 Acc 0.576\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/15] Training Step 000 Loss 1.353 Acc 0.516\n",
      "[  2/15] Training Step 100 Loss 1.131 Acc 0.578\n",
      "[  2/15] Training Step 200 Loss 1.028 Acc 0.562\n",
      "[  2/15] Training Step 300 Loss 1.237 Acc 0.531\n",
      "[  2/15] Training Step 400 Loss 0.942 Acc 0.641\n",
      "[  2/15] Training Step 500 Loss 1.194 Acc 0.562\n",
      "[  2/15] Training Step 600 Loss 0.906 Acc 0.688\n",
      "[  2/15] Training Step 700 Loss 0.979 Acc 0.703\n",
      "[  2/15] Validate Step 015 Loss 1.012 Acc 0.639\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/15] Training Step 000 Loss 1.050 Acc 0.547\n",
      "[  3/15] Training Step 100 Loss 0.821 Acc 0.781\n",
      "[  3/15] Training Step 200 Loss 0.844 Acc 0.672\n",
      "[  3/15] Training Step 300 Loss 0.965 Acc 0.656\n",
      "[  3/15] Training Step 400 Loss 0.919 Acc 0.656\n",
      "[  3/15] Training Step 500 Loss 0.813 Acc 0.703\n",
      "[  3/15] Training Step 600 Loss 1.009 Acc 0.672\n",
      "[  3/15] Training Step 700 Loss 1.257 Acc 0.641\n",
      "[  3/15] Validate Step 015 Loss 0.909 Acc 0.699\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/15] Training Step 000 Loss 0.656 Acc 0.797\n",
      "[  4/15] Training Step 100 Loss 0.754 Acc 0.703\n",
      "[  4/15] Training Step 200 Loss 0.839 Acc 0.750\n",
      "[  4/15] Training Step 300 Loss 0.849 Acc 0.703\n",
      "[  4/15] Training Step 400 Loss 0.866 Acc 0.688\n",
      "[  4/15] Training Step 500 Loss 0.565 Acc 0.812\n",
      "[  4/15] Training Step 600 Loss 0.841 Acc 0.656\n",
      "[  4/15] Training Step 700 Loss 0.737 Acc 0.719\n",
      "[  4/15] Validate Step 015 Loss 0.846 Acc 0.704\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/15] Training Step 000 Loss 0.610 Acc 0.750\n",
      "[  5/15] Training Step 100 Loss 0.503 Acc 0.812\n",
      "[  5/15] Training Step 200 Loss 0.679 Acc 0.703\n",
      "[  5/15] Training Step 300 Loss 0.522 Acc 0.859\n",
      "[  5/15] Training Step 400 Loss 0.594 Acc 0.781\n",
      "[  5/15] Training Step 500 Loss 0.806 Acc 0.734\n",
      "[  5/15] Training Step 600 Loss 0.743 Acc 0.719\n",
      "[  5/15] Training Step 700 Loss 0.547 Acc 0.859\n",
      "[  5/15] Validate Step 015 Loss 0.765 Acc 0.753\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/15] Training Step 000 Loss 0.691 Acc 0.734\n",
      "[  6/15] Training Step 100 Loss 0.734 Acc 0.766\n",
      "[  6/15] Training Step 200 Loss 0.695 Acc 0.734\n",
      "[  6/15] Training Step 300 Loss 0.500 Acc 0.828\n",
      "[  6/15] Training Step 400 Loss 0.795 Acc 0.750\n",
      "[  6/15] Training Step 500 Loss 0.454 Acc 0.812\n",
      "[  6/15] Training Step 600 Loss 0.777 Acc 0.703\n",
      "[  6/15] Training Step 700 Loss 0.341 Acc 0.875\n",
      "[  6/15] Validate Step 015 Loss 0.785 Acc 0.735\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/15] Training Step 000 Loss 0.367 Acc 0.875\n",
      "[  7/15] Training Step 100 Loss 0.635 Acc 0.750\n",
      "[  7/15] Training Step 200 Loss 0.385 Acc 0.844\n",
      "[  7/15] Training Step 300 Loss 0.556 Acc 0.828\n",
      "[  7/15] Training Step 400 Loss 0.613 Acc 0.734\n",
      "[  7/15] Training Step 500 Loss 0.265 Acc 0.891\n",
      "[  7/15] Training Step 600 Loss 0.420 Acc 0.859\n",
      "[  7/15] Training Step 700 Loss 0.456 Acc 0.859\n",
      "[  7/15] Validate Step 015 Loss 0.805 Acc 0.732\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/15] Training Step 000 Loss 0.280 Acc 0.891\n",
      "[  8/15] Training Step 100 Loss 0.456 Acc 0.797\n",
      "[  8/15] Training Step 200 Loss 0.320 Acc 0.906\n",
      "[  8/15] Training Step 300 Loss 0.403 Acc 0.859\n",
      "[  8/15] Training Step 400 Loss 0.412 Acc 0.859\n",
      "[  8/15] Training Step 500 Loss 0.351 Acc 0.891\n",
      "[  8/15] Training Step 600 Loss 0.316 Acc 0.906\n",
      "[  8/15] Training Step 700 Loss 0.226 Acc 0.938\n",
      "[  8/15] Validate Step 015 Loss 0.811 Acc 0.742\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/15] Training Step 000 Loss 0.263 Acc 0.891\n",
      "[  9/15] Training Step 100 Loss 0.336 Acc 0.875\n",
      "[  9/15] Training Step 200 Loss 0.256 Acc 0.938\n",
      "[  9/15] Training Step 300 Loss 0.239 Acc 0.906\n",
      "[  9/15] Training Step 400 Loss 0.247 Acc 0.969\n",
      "[  9/15] Training Step 500 Loss 0.281 Acc 0.938\n",
      "[  9/15] Training Step 600 Loss 0.270 Acc 0.906\n",
      "[  9/15] Training Step 700 Loss 0.310 Acc 0.906\n",
      "[  9/15] Validate Step 015 Loss 0.854 Acc 0.737\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/15] Training Step 000 Loss 0.283 Acc 0.922\n",
      "[ 10/15] Training Step 100 Loss 0.246 Acc 0.953\n",
      "[ 10/15] Training Step 200 Loss 0.183 Acc 0.938\n",
      "[ 10/15] Training Step 300 Loss 0.196 Acc 0.922\n",
      "[ 10/15] Training Step 400 Loss 0.288 Acc 0.953\n",
      "[ 10/15] Training Step 500 Loss 0.152 Acc 0.969\n",
      "[ 10/15] Training Step 600 Loss 0.171 Acc 0.938\n",
      "[ 10/15] Training Step 700 Loss 0.250 Acc 0.922\n",
      "[ 10/15] Validate Step 015 Loss 0.862 Acc 0.749\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/15] Training Step 000 Loss 0.093 Acc 1.000\n",
      "[ 11/15] Training Step 100 Loss 0.120 Acc 0.984\n",
      "[ 11/15] Training Step 200 Loss 0.142 Acc 0.969\n",
      "[ 11/15] Training Step 300 Loss 0.127 Acc 0.953\n",
      "[ 11/15] Training Step 400 Loss 0.107 Acc 0.969\n",
      "[ 11/15] Training Step 500 Loss 0.143 Acc 0.953\n",
      "[ 11/15] Training Step 600 Loss 0.106 Acc 0.969\n",
      "[ 11/15] Training Step 700 Loss 0.155 Acc 0.953\n",
      "[ 11/15] Validate Step 015 Loss 0.954 Acc 0.737\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/15] Training Step 000 Loss 0.133 Acc 0.953\n",
      "[ 12/15] Training Step 100 Loss 0.080 Acc 1.000\n",
      "[ 12/15] Training Step 200 Loss 0.078 Acc 1.000\n",
      "[ 12/15] Training Step 300 Loss 0.087 Acc 0.984\n",
      "[ 12/15] Training Step 400 Loss 0.080 Acc 0.969\n",
      "[ 12/15] Training Step 500 Loss 0.120 Acc 0.969\n",
      "[ 12/15] Training Step 600 Loss 0.079 Acc 0.984\n",
      "[ 12/15] Training Step 700 Loss 0.079 Acc 0.984\n",
      "[ 12/15] Validate Step 015 Loss 0.924 Acc 0.749\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/15] Training Step 000 Loss 0.043 Acc 1.000\n",
      "[ 13/15] Training Step 100 Loss 0.044 Acc 1.000\n",
      "[ 13/15] Training Step 200 Loss 0.031 Acc 1.000\n",
      "[ 13/15] Training Step 300 Loss 0.020 Acc 1.000\n",
      "[ 13/15] Training Step 400 Loss 0.085 Acc 0.969\n",
      "[ 13/15] Training Step 500 Loss 0.046 Acc 1.000\n",
      "[ 13/15] Training Step 600 Loss 0.064 Acc 0.984\n",
      "[ 13/15] Training Step 700 Loss 0.065 Acc 0.984\n",
      "[ 13/15] Validate Step 015 Loss 0.980 Acc 0.748\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/15] Training Step 000 Loss 0.027 Acc 1.000\n",
      "[ 14/15] Training Step 100 Loss 0.052 Acc 0.984\n",
      "[ 14/15] Training Step 200 Loss 0.016 Acc 1.000\n",
      "[ 14/15] Training Step 300 Loss 0.023 Acc 1.000\n",
      "[ 14/15] Training Step 400 Loss 0.022 Acc 1.000\n",
      "[ 14/15] Training Step 500 Loss 0.017 Acc 1.000\n",
      "[ 14/15] Training Step 600 Loss 0.018 Acc 1.000\n",
      "[ 14/15] Training Step 700 Loss 0.040 Acc 1.000\n",
      "[ 14/15] Validate Step 015 Loss 0.926 Acc 0.771\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/15] Training Step 000 Loss 0.020 Acc 1.000\n",
      "[ 15/15] Training Step 100 Loss 0.009 Acc 1.000\n",
      "[ 15/15] Training Step 200 Loss 0.010 Acc 1.000\n",
      "[ 15/15] Training Step 300 Loss 0.028 Acc 0.984\n",
      "[ 15/15] Training Step 400 Loss 0.019 Acc 1.000\n",
      "[ 15/15] Training Step 500 Loss 0.011 Acc 1.000\n",
      "[ 15/15] Training Step 600 Loss 0.012 Acc 1.000\n",
      "[ 15/15] Training Step 700 Loss 0.023 Acc 1.000\n",
      "[ 15/15] Validate Step 015 Loss 0.956 Acc 0.759\n",
      "---------------- Testing ----------------\n",
      "[  1/15] Testing Step 156 Loss 1.066 Acc 0.737\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "optimizer = None\n",
    "###############################################################################\n",
    "#                               TODO                                          #\n",
    "###############################################################################          \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, bias=0),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, bias=0),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, bias=0),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, stride=1, bias=0),\n",
    "    nn.BatchNorm2d(96),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=96, out_channels=128, kernel_size=3, stride=2, bias=0),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.ReLU(),nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, bias=0),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(256*5*5, 200, bias=0),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 10, bias=0),\n",
    "    )\n",
    "###############################################################################\n",
    "#                            END TO DO                                        #\n",
    "###############################################################################  \n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請解釋你如何建構的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--寫在這裡--\n",
    "總共有6層convolution層，\n",
    "每一層做完後都進行 BatchNormalization 以及 ReLU，\n",
    "卷積層後做Flatten，\n",
    "最後接到兩層全連接層"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
