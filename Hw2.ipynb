{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch homework\n",
    "## 作業說明\n",
    "這次的作業總共有5個部份，在每一個部份會有一些被註解框起來的區塊需要完成。\n",
    "1. Preparation: 我們會利用CIFAR-10 dataset **(10%)**\n",
    "2. Pytorch Module API: 在這邊我們會利用 nn.Module 建構出簡單的CNN（CNN架構請參照我們所提供） **(20%)**\n",
    "3. Pytorch ModuleList API: 在這邊我們 nn.ModuleList 以及 nn.Module來建構出簡單的CNN（CNN架構請參照我們所提供） **(20%)**\n",
    "4. Pytorch Sequential API: 在這邊我們 nn.Sequential 來建構出簡單的CNN（CNN架構請參照我們所提供） **(20%)**\n",
    "5. CIFAR-10 open-ended challenge: 在這邊請大家建構屬於自己的CNN，並且盡量的得到高準確度，並解釋如何建構的 **(30%)**\n",
    "    * 可以嘗試建構任意的layer, optimizer或是 hyperparameters等\n",
    "    * 由於並不是所有同學都有GPU可以提供training，因此這題分數的分配不是根據最後的準確度而給分，而是達到baseline之後便會給於全部的分數\n",
    "    * **Baseline: 65% on testing data**\n",
    "    \n",
    "## 作業繳交\n",
    "* Deadline : 11/06 中午12:00\n",
    "    * **遲交一天的打7折**\n",
    "    * **遲交一天以上的打5折**\n",
    "* 繳交方式 : 請繳交這個ipynb檔至moodle\n",
    "* 作業命名 : (你的學號)\\_(姓名)\\_hw2.ipynb  (ex.F71112222_人工智.ipynb) \n",
    "    * **格式不對的話會扣10分！！！**\n",
    "* 有任何問題歡迎寄信至我的信箱\n",
    "    * 黃顯堯 e0928021388@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n",
    "你可以根據需求調整epochs, batch size等等的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "CIFAR_STD = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 64\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 49000\n",
    "\n",
    "CUDA = True\n",
    "\n",
    "PATH_TO_SAVE_DATA = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "                  ])\n",
    "\n",
    "train_data = datasets.CIFAR10(root=PATH_TO_SAVE_DATA, train=True,\n",
    "                              download=True, transform=data_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                          sampler=SubsetRandomSampler(range(TRAIN_NUMS)))\n",
    "val_loader = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        sampler=SubsetRandomSampler(range(TRAIN_NUMS, 50000)))\n",
    "\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(root=PATH_TO_SAVE_DATA, train=False,\n",
    "                             download=True, transform=data_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU setting\n",
    "可以根據選擇是否要使用gpu，在本次的作業沒有一定要使用到gpu，假如你沒有安裝cuda，torch.cuda.is_available會return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer\n",
    "我們有提供Trainer讓同學可以training自己建構的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "            print(\"---------------- Epoch {} ----------------\".format(epoch))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        \n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "                \n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening: torch.Size([10, 3, 32, 32])\n",
      "After flattening: torch.Size([10, 3072])\n"
     ]
    }
   ],
   "source": [
    "def flatten(x):    \n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "#     x = x.view(x.shape[0], x.shape[1]*x.shape[2]*x.shape[3])\n",
    "    return x\n",
    "\n",
    "def test_flatten():\n",
    "    x = torch.zeros((10, 3, 32, 32))\n",
    "    print(\"Before flattening:\", x.shape)\n",
    "    print(\"After flattening:\", flatten(x).shape) # Expected output (10, 3072) \n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 : Module API\n",
    "In this part, you have to complete the implentation of CNN with Module API.\n",
    "The network should have the following architectures.\n",
    "1. A convolution layer with 16 3\\*3 filters, with stride 2\n",
    "2. ReLU\n",
    "3. A convolution layer with 32 3\\*3 filters, with stride 2\n",
    "4. ReLU\n",
    "5. Flatten\n",
    "6. A fully-connected layer produce tensor to 200 \n",
    "7. ReLU\n",
    "8. A fully-connected layer produce score to 10 (classes)\n",
    "![](./resource/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"537pt\"\n",
       " viewBox=\"0.00 0.00 335.50 537.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 533)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-533 331.5,-533 331.5,4 -4,4\"/>\n",
       "<!-- 140471981468864 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140471981468864</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"282.5,-21 197.5,-21 197.5,0 282.5,0 282.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140471981203528 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140471981203528</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"236,-78 142,-78 142,-57 236,-57 236,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981203528&#45;&gt;140471981468864 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140471981203528&#45;&gt;140471981468864</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.5927,-56.7787C205.6449,-48.8969 215.3997,-37.9944 223.6699,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.3907,-30.9594 230.4503,-21.1732 221.174,-26.2918 226.3907,-30.9594\"/>\n",
       "</g>\n",
       "<!-- 140471981203696 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140471981203696</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231.5,-141.5 146.5,-141.5 146.5,-120.5 231.5,-120.5 231.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140471981203696&#45;&gt;140471981203528 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140471981203696&#45;&gt;140471981203528</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189,-120.2281C189,-111.5091 189,-98.9699 189,-88.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.5001,-88.1128 189,-78.1128 185.5001,-88.1129 192.5001,-88.1128\"/>\n",
       "</g>\n",
       "<!-- 140471981203808 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140471981203808</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"190.5,-205 77.5,-205 77.5,-184 190.5,-184 190.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140471981203808&#45;&gt;140471981203696 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140471981203808&#45;&gt;140471981203696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.33,-183.7281C151.4383,-174.3667 163.3611,-160.6012 172.9914,-149.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"175.9063,-151.4632 179.8078,-141.6128 170.6151,-146.8802 175.9063,-151.4632\"/>\n",
       "</g>\n",
       "<!-- 140471981203976 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140471981203976</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"181,-268.5 87,-268.5 87,-247.5 181,-247.5 181,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981203976&#45;&gt;140471981203808 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140471981203976&#45;&gt;140471981203808</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-247.2281C134,-238.5091 134,-225.9699 134,-215.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-215.1128 134,-205.1128 130.5001,-215.1129 137.5001,-215.1128\"/>\n",
       "</g>\n",
       "<!-- 140471981204088 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140471981204088</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"215,-332 53,-332 53,-311 215,-311 215,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140471981204088&#45;&gt;140471981203976 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140471981204088&#45;&gt;140471981203976</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-310.7281C134,-302.0091 134,-289.4699 134,-278.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-278.6128 134,-268.6128 130.5001,-278.6129 137.5001,-278.6128\"/>\n",
       "</g>\n",
       "<!-- 140471981204200 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140471981204200</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-395.5 34,-395.5 34,-374.5 128,-374.5 128,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981204200&#45;&gt;140471981204088 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140471981204200&#45;&gt;140471981204088</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.9907,-374.2281C97.8042,-364.8667 109.2935,-351.1012 118.5736,-339.9826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.4213,-342.0328 125.1421,-332.1128 116.0472,-337.5474 121.4213,-342.0328\"/>\n",
       "</g>\n",
       "<!-- 140471981204368 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140471981204368</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-459 0,-459 0,-438 162,-438 162,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140471981204368&#45;&gt;140471981204200 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140471981204368&#45;&gt;140471981204200</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-437.7281C81,-429.0091 81,-416.4699 81,-405.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-405.6128 81,-395.6128 77.5001,-405.6129 84.5001,-405.6128\"/>\n",
       "</g>\n",
       "<!-- 140471981204480 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140471981204480</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"121.5,-529 40.5,-529 40.5,-495 121.5,-495 121.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140471981204480&#45;&gt;140471981204368 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140471981204480&#45;&gt;140471981204368</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-494.9832C81,-487.1157 81,-477.6973 81,-469.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-469.3686 81,-459.3687 77.5001,-469.3687 84.5001,-469.3686\"/>\n",
       "</g>\n",
       "<!-- 140471981204256 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140471981204256</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"227.5,-402 146.5,-402 146.5,-368 227.5,-368 227.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140471981204256&#45;&gt;140471981204088 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140471981204256&#45;&gt;140471981204088</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.797,-367.9832C165.6401,-359.4085 156.9458,-348.9916 149.603,-340.1942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.1664,-337.8032 143.0715,-332.3687 146.7923,-342.2887 152.1664,-337.8032\"/>\n",
       "</g>\n",
       "<!-- 140471981203864 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140471981203864</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"281.5,-205 208.5,-205 208.5,-184 281.5,-184 281.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140471981203864&#45;&gt;140471981203696 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140471981203864&#45;&gt;140471981203696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.5004,-183.7281C227.1637,-174.2749 214.8666,-160.3309 205.0119,-149.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.5987,-146.7979 198.3593,-141.6128 202.3486,-151.428 207.5987,-146.7979\"/>\n",
       "</g>\n",
       "<!-- 140471981204032 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140471981204032</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"282.5,-275 207.5,-275 207.5,-241 282.5,-241 282.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (200, 1568)</text>\n",
       "</g>\n",
       "<!-- 140471981204032&#45;&gt;140471981203864 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140471981204032&#45;&gt;140471981203864</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245,-240.9832C245,-233.1157 245,-223.6973 245,-215.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.5001,-215.3686 245,-205.3687 241.5001,-215.3687 248.5001,-215.3686\"/>\n",
       "</g>\n",
       "<!-- 140471981203584 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140471981203584</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"327.5,-78 254.5,-78 254.5,-57 327.5,-57 327.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140471981203584&#45;&gt;140471981468864 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140471981203584&#45;&gt;140471981468864</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.4073,-56.7787C274.3551,-48.8969 264.6003,-37.9944 256.3301,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.826,-26.2918 249.5497,-21.1732 253.6093,-30.9594 258.826,-26.2918\"/>\n",
       "</g>\n",
       "<!-- 140471981203752 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140471981203752</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"324.5,-148 257.5,-148 257.5,-114 324.5,-114 324.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 200)</text>\n",
       "</g>\n",
       "<!-- 140471981203752&#45;&gt;140471981203584 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140471981203752&#45;&gt;140471981203584</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291,-113.9832C291,-106.1157 291,-96.6973 291,-88.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.5001,-88.3686 291,-78.3687 287.5001,-88.3687 294.5001,-88.3686\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc257f698d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1, self.conv2 = None, None\n",
    "        self.fc1, self.fc2 = None, None\n",
    "        ###############################################################################\n",
    "        #       TODO : Set up the layer that you need to construct the model          #\n",
    "        ###############################################################################\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, bias=0)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32*7*7, 200, bias=0)\n",
    "        self.fc2 = nn.Linear(200, 10, bias=0)\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        ###############################################################################\n",
    "        #            TODO : Implement the forward function. You should use            #\n",
    "        #                   the layers you defined in __init__ and specify the        #\n",
    "        #                   connectivity of those layers in forward()                 #\n",
    "        ###############################################################################\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(x.shape)\n",
    "        # x = F.relu(self.conv3(x))\n",
    "        # print(x.shape)\n",
    "        x = flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################\n",
    "    \n",
    "        return out\n",
    "        \n",
    "\n",
    "model = CNN()\n",
    "x = torch.zeros((BATCH_SIZE, 3, 32, 32))\n",
    "make_dot(model(x), params=dict(model.named_parameters())) # You can check if the picture is the same \n",
    "                                                          # as previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Train the model and check the accuracy of training dataset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.298 Acc 0.109\n",
      "[  1/25] Training Step 100 Loss 2.270 Acc 0.125\n",
      "[  1/25] Training Step 200 Loss 2.212 Acc 0.250\n",
      "[  1/25] Training Step 300 Loss 2.046 Acc 0.219\n",
      "[  1/25] Training Step 400 Loss 1.911 Acc 0.281\n",
      "[  1/25] Training Step 500 Loss 1.883 Acc 0.312\n",
      "[  1/25] Training Step 600 Loss 1.813 Acc 0.406\n",
      "[  1/25] Training Step 700 Loss 1.597 Acc 0.469\n",
      "[  1/25] Validate Step 015 Loss 1.826 Acc 0.370\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 1.609 Acc 0.484\n",
      "[  2/25] Training Step 100 Loss 1.641 Acc 0.422\n",
      "[  2/25] Training Step 200 Loss 1.858 Acc 0.375\n",
      "[  2/25] Training Step 300 Loss 1.824 Acc 0.297\n",
      "[  2/25] Training Step 400 Loss 1.815 Acc 0.406\n",
      "[  2/25] Training Step 500 Loss 1.618 Acc 0.422\n",
      "[  2/25] Training Step 600 Loss 1.874 Acc 0.297\n",
      "[  2/25] Training Step 700 Loss 1.325 Acc 0.516\n",
      "[  2/25] Validate Step 015 Loss 1.642 Acc 0.427\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.596 Acc 0.438\n",
      "[  3/25] Training Step 100 Loss 1.405 Acc 0.484\n",
      "[  3/25] Training Step 200 Loss 1.612 Acc 0.562\n",
      "[  3/25] Training Step 300 Loss 1.500 Acc 0.453\n",
      "[  3/25] Training Step 400 Loss 1.333 Acc 0.516\n",
      "[  3/25] Training Step 500 Loss 1.520 Acc 0.516\n",
      "[  3/25] Training Step 600 Loss 1.666 Acc 0.469\n",
      "[  3/25] Training Step 700 Loss 1.581 Acc 0.453\n",
      "[  3/25] Validate Step 015 Loss 1.529 Acc 0.451\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.330 Acc 0.484\n",
      "[  4/25] Training Step 100 Loss 1.357 Acc 0.609\n",
      "[  4/25] Training Step 200 Loss 1.452 Acc 0.453\n",
      "[  4/25] Training Step 300 Loss 1.447 Acc 0.453\n",
      "[  4/25] Training Step 400 Loss 1.529 Acc 0.422\n",
      "[  4/25] Training Step 500 Loss 1.615 Acc 0.422\n",
      "[  4/25] Training Step 600 Loss 1.406 Acc 0.516\n",
      "[  4/25] Training Step 700 Loss 1.257 Acc 0.578\n",
      "[  4/25] Validate Step 015 Loss 1.442 Acc 0.488\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.450 Acc 0.469\n",
      "[  5/25] Training Step 100 Loss 1.262 Acc 0.609\n",
      "[  5/25] Training Step 200 Loss 1.431 Acc 0.469\n",
      "[  5/25] Training Step 300 Loss 1.415 Acc 0.453\n",
      "[  5/25] Training Step 400 Loss 1.392 Acc 0.531\n",
      "[  5/25] Training Step 500 Loss 1.565 Acc 0.422\n",
      "[  5/25] Training Step 600 Loss 1.326 Acc 0.516\n",
      "[  5/25] Training Step 700 Loss 1.357 Acc 0.531\n",
      "[  5/25] Validate Step 015 Loss 1.387 Acc 0.514\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.497 Acc 0.547\n",
      "[  6/25] Training Step 100 Loss 1.345 Acc 0.562\n",
      "[  6/25] Training Step 200 Loss 1.269 Acc 0.547\n",
      "[  6/25] Training Step 300 Loss 1.531 Acc 0.500\n",
      "[  6/25] Training Step 400 Loss 1.606 Acc 0.484\n",
      "[  6/25] Training Step 500 Loss 1.276 Acc 0.500\n",
      "[  6/25] Training Step 600 Loss 1.304 Acc 0.562\n",
      "[  6/25] Training Step 700 Loss 1.275 Acc 0.562\n",
      "[  6/25] Validate Step 015 Loss 1.343 Acc 0.527\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.254 Acc 0.578\n",
      "[  7/25] Training Step 100 Loss 1.236 Acc 0.500\n",
      "[  7/25] Training Step 200 Loss 1.154 Acc 0.578\n",
      "[  7/25] Training Step 300 Loss 1.252 Acc 0.500\n",
      "[  7/25] Training Step 400 Loss 1.053 Acc 0.625\n",
      "[  7/25] Training Step 500 Loss 1.249 Acc 0.688\n",
      "[  7/25] Training Step 600 Loss 1.237 Acc 0.609\n",
      "[  7/25] Training Step 700 Loss 1.055 Acc 0.625\n",
      "[  7/25] Validate Step 015 Loss 1.295 Acc 0.557\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 1.152 Acc 0.625\n",
      "[  8/25] Training Step 100 Loss 1.426 Acc 0.531\n",
      "[  8/25] Training Step 200 Loss 0.904 Acc 0.719\n",
      "[  8/25] Training Step 300 Loss 1.266 Acc 0.500\n",
      "[  8/25] Training Step 400 Loss 1.186 Acc 0.641\n",
      "[  8/25] Training Step 500 Loss 1.274 Acc 0.500\n",
      "[  8/25] Training Step 600 Loss 1.229 Acc 0.578\n",
      "[  8/25] Training Step 700 Loss 1.494 Acc 0.516\n",
      "[  8/25] Validate Step 015 Loss 1.254 Acc 0.559\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 0.951 Acc 0.672\n",
      "[  9/25] Training Step 100 Loss 1.308 Acc 0.500\n",
      "[  9/25] Training Step 200 Loss 1.395 Acc 0.500\n",
      "[  9/25] Training Step 300 Loss 1.140 Acc 0.594\n",
      "[  9/25] Training Step 400 Loss 1.076 Acc 0.594\n",
      "[  9/25] Training Step 500 Loss 1.070 Acc 0.609\n",
      "[  9/25] Training Step 600 Loss 1.231 Acc 0.625\n",
      "[  9/25] Training Step 700 Loss 1.175 Acc 0.656\n",
      "[  9/25] Validate Step 015 Loss 1.222 Acc 0.580\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 1.164 Acc 0.547\n",
      "[ 10/25] Training Step 100 Loss 1.129 Acc 0.703\n",
      "[ 10/25] Training Step 200 Loss 1.156 Acc 0.625\n",
      "[ 10/25] Training Step 300 Loss 1.104 Acc 0.609\n",
      "[ 10/25] Training Step 400 Loss 1.100 Acc 0.562\n",
      "[ 10/25] Training Step 500 Loss 1.240 Acc 0.609\n",
      "[ 10/25] Training Step 600 Loss 1.113 Acc 0.547\n",
      "[ 10/25] Training Step 700 Loss 1.178 Acc 0.578\n",
      "[ 10/25] Validate Step 015 Loss 1.173 Acc 0.585\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 1.330 Acc 0.562\n",
      "[ 11/25] Training Step 100 Loss 1.219 Acc 0.609\n",
      "[ 11/25] Training Step 200 Loss 1.094 Acc 0.562\n",
      "[ 11/25] Training Step 300 Loss 0.906 Acc 0.703\n",
      "[ 11/25] Training Step 400 Loss 1.284 Acc 0.547\n",
      "[ 11/25] Training Step 500 Loss 0.966 Acc 0.609\n",
      "[ 11/25] Training Step 600 Loss 1.083 Acc 0.625\n",
      "[ 11/25] Training Step 700 Loss 1.002 Acc 0.719\n",
      "[ 11/25] Validate Step 015 Loss 1.162 Acc 0.606\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 1.058 Acc 0.656\n",
      "[ 12/25] Training Step 100 Loss 1.230 Acc 0.562\n",
      "[ 12/25] Training Step 200 Loss 0.874 Acc 0.672\n",
      "[ 12/25] Training Step 300 Loss 0.848 Acc 0.781\n",
      "[ 12/25] Training Step 400 Loss 1.336 Acc 0.594\n",
      "[ 12/25] Training Step 500 Loss 0.931 Acc 0.641\n",
      "[ 12/25] Training Step 600 Loss 1.370 Acc 0.469\n",
      "[ 12/25] Training Step 700 Loss 1.103 Acc 0.656\n",
      "[ 12/25] Validate Step 015 Loss 1.159 Acc 0.587\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.910 Acc 0.688\n",
      "[ 13/25] Training Step 100 Loss 0.955 Acc 0.641\n",
      "[ 13/25] Training Step 200 Loss 1.042 Acc 0.625\n",
      "[ 13/25] Training Step 300 Loss 1.112 Acc 0.656\n",
      "[ 13/25] Training Step 400 Loss 1.016 Acc 0.688\n",
      "[ 13/25] Training Step 500 Loss 1.324 Acc 0.453\n",
      "[ 13/25] Training Step 600 Loss 0.983 Acc 0.547\n",
      "[ 13/25] Training Step 700 Loss 1.073 Acc 0.641\n",
      "[ 13/25] Validate Step 015 Loss 1.128 Acc 0.614\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 1.105 Acc 0.578\n",
      "[ 14/25] Training Step 100 Loss 1.014 Acc 0.594\n",
      "[ 14/25] Training Step 200 Loss 0.914 Acc 0.734\n",
      "[ 14/25] Training Step 300 Loss 0.931 Acc 0.656\n",
      "[ 14/25] Training Step 400 Loss 1.015 Acc 0.641\n",
      "[ 14/25] Training Step 500 Loss 0.945 Acc 0.641\n",
      "[ 14/25] Training Step 600 Loss 0.998 Acc 0.641\n",
      "[ 14/25] Training Step 700 Loss 0.948 Acc 0.656\n",
      "[ 14/25] Validate Step 015 Loss 1.119 Acc 0.618\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.824 Acc 0.688\n",
      "[ 15/25] Training Step 100 Loss 0.922 Acc 0.734\n",
      "[ 15/25] Training Step 200 Loss 1.176 Acc 0.656\n",
      "[ 15/25] Training Step 300 Loss 1.106 Acc 0.672\n",
      "[ 15/25] Training Step 400 Loss 1.144 Acc 0.578\n",
      "[ 15/25] Training Step 500 Loss 0.755 Acc 0.750\n",
      "[ 15/25] Training Step 600 Loss 0.775 Acc 0.781\n",
      "[ 15/25] Training Step 700 Loss 0.765 Acc 0.734\n",
      "[ 15/25] Validate Step 015 Loss 1.128 Acc 0.626\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.797 Acc 0.766\n",
      "[ 16/25] Training Step 100 Loss 0.903 Acc 0.641\n",
      "[ 16/25] Training Step 200 Loss 0.658 Acc 0.797\n",
      "[ 16/25] Training Step 300 Loss 0.671 Acc 0.781\n",
      "[ 16/25] Training Step 400 Loss 0.923 Acc 0.734\n",
      "[ 16/25] Training Step 500 Loss 0.986 Acc 0.594\n",
      "[ 16/25] Training Step 600 Loss 0.723 Acc 0.734\n",
      "[ 16/25] Training Step 700 Loss 1.112 Acc 0.719\n",
      "[ 16/25] Validate Step 015 Loss 1.105 Acc 0.632\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.753 Acc 0.734\n",
      "[ 17/25] Training Step 100 Loss 0.881 Acc 0.719\n",
      "[ 17/25] Training Step 200 Loss 0.954 Acc 0.625\n",
      "[ 17/25] Training Step 300 Loss 0.509 Acc 0.797\n",
      "[ 17/25] Training Step 400 Loss 0.827 Acc 0.688\n",
      "[ 17/25] Training Step 500 Loss 0.865 Acc 0.688\n",
      "[ 17/25] Training Step 600 Loss 0.831 Acc 0.734\n",
      "[ 17/25] Training Step 700 Loss 1.153 Acc 0.594\n",
      "[ 17/25] Validate Step 015 Loss 1.144 Acc 0.616\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 1.242 Acc 0.609\n",
      "[ 18/25] Training Step 100 Loss 0.860 Acc 0.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.792 Acc 0.734\n",
      "[ 18/25] Training Step 300 Loss 0.671 Acc 0.719\n",
      "[ 18/25] Training Step 400 Loss 0.791 Acc 0.719\n",
      "[ 18/25] Training Step 500 Loss 0.767 Acc 0.766\n",
      "[ 18/25] Training Step 600 Loss 0.833 Acc 0.750\n",
      "[ 18/25] Training Step 700 Loss 0.871 Acc 0.625\n",
      "[ 18/25] Validate Step 015 Loss 1.103 Acc 0.620\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.860 Acc 0.703\n",
      "[ 19/25] Training Step 100 Loss 0.643 Acc 0.828\n",
      "[ 19/25] Training Step 200 Loss 0.952 Acc 0.688\n",
      "[ 19/25] Training Step 300 Loss 0.913 Acc 0.656\n",
      "[ 19/25] Training Step 400 Loss 0.679 Acc 0.781\n",
      "[ 19/25] Training Step 500 Loss 0.832 Acc 0.797\n",
      "[ 19/25] Training Step 600 Loss 0.889 Acc 0.703\n",
      "[ 19/25] Training Step 700 Loss 0.591 Acc 0.797\n",
      "[ 19/25] Validate Step 015 Loss 1.148 Acc 0.614\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.624 Acc 0.797\n",
      "[ 20/25] Training Step 100 Loss 0.769 Acc 0.734\n",
      "[ 20/25] Training Step 200 Loss 0.815 Acc 0.703\n",
      "[ 20/25] Training Step 300 Loss 0.464 Acc 0.844\n",
      "[ 20/25] Training Step 400 Loss 0.658 Acc 0.750\n",
      "[ 20/25] Training Step 500 Loss 0.800 Acc 0.719\n",
      "[ 20/25] Training Step 600 Loss 0.679 Acc 0.812\n",
      "[ 20/25] Training Step 700 Loss 1.021 Acc 0.688\n",
      "[ 20/25] Validate Step 015 Loss 1.159 Acc 0.612\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.831 Acc 0.688\n",
      "[ 21/25] Training Step 100 Loss 0.686 Acc 0.766\n",
      "[ 21/25] Training Step 200 Loss 0.659 Acc 0.750\n",
      "[ 21/25] Training Step 300 Loss 0.931 Acc 0.703\n",
      "[ 21/25] Training Step 400 Loss 0.729 Acc 0.781\n",
      "[ 21/25] Training Step 500 Loss 0.745 Acc 0.750\n",
      "[ 21/25] Training Step 600 Loss 0.687 Acc 0.781\n",
      "[ 21/25] Training Step 700 Loss 0.702 Acc 0.781\n",
      "[ 21/25] Validate Step 015 Loss 1.143 Acc 0.626\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.519 Acc 0.812\n",
      "[ 22/25] Training Step 100 Loss 0.533 Acc 0.812\n",
      "[ 22/25] Training Step 200 Loss 0.818 Acc 0.719\n",
      "[ 22/25] Training Step 300 Loss 0.762 Acc 0.734\n",
      "[ 22/25] Training Step 400 Loss 0.497 Acc 0.750\n",
      "[ 22/25] Training Step 500 Loss 0.764 Acc 0.781\n",
      "[ 22/25] Training Step 600 Loss 0.637 Acc 0.750\n",
      "[ 22/25] Training Step 700 Loss 0.655 Acc 0.750\n",
      "[ 22/25] Validate Step 015 Loss 1.207 Acc 0.616\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.631 Acc 0.812\n",
      "[ 23/25] Training Step 100 Loss 0.402 Acc 0.875\n",
      "[ 23/25] Training Step 200 Loss 0.584 Acc 0.812\n",
      "[ 23/25] Training Step 300 Loss 0.608 Acc 0.750\n",
      "[ 23/25] Training Step 400 Loss 0.619 Acc 0.781\n",
      "[ 23/25] Training Step 500 Loss 0.572 Acc 0.734\n",
      "[ 23/25] Training Step 600 Loss 0.720 Acc 0.797\n",
      "[ 23/25] Training Step 700 Loss 0.708 Acc 0.750\n",
      "[ 23/25] Validate Step 015 Loss 1.261 Acc 0.601\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.506 Acc 0.797\n",
      "[ 24/25] Training Step 100 Loss 0.722 Acc 0.812\n",
      "[ 24/25] Training Step 200 Loss 0.489 Acc 0.828\n",
      "[ 24/25] Training Step 300 Loss 0.414 Acc 0.828\n",
      "[ 24/25] Training Step 400 Loss 0.576 Acc 0.734\n",
      "[ 24/25] Training Step 500 Loss 0.493 Acc 0.875\n",
      "[ 24/25] Training Step 600 Loss 0.450 Acc 0.797\n",
      "[ 24/25] Training Step 700 Loss 0.450 Acc 0.875\n",
      "[ 24/25] Validate Step 015 Loss 1.241 Acc 0.616\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.455 Acc 0.828\n",
      "[ 25/25] Training Step 100 Loss 0.305 Acc 0.922\n",
      "[ 25/25] Training Step 200 Loss 0.527 Acc 0.797\n",
      "[ 25/25] Training Step 300 Loss 0.486 Acc 0.797\n",
      "[ 25/25] Training Step 400 Loss 0.704 Acc 0.672\n",
      "[ 25/25] Training Step 500 Loss 0.464 Acc 0.812\n",
      "[ 25/25] Training Step 600 Loss 0.444 Acc 0.812\n",
      "[ 25/25] Training Step 700 Loss 0.502 Acc 0.844\n",
      "[ 25/25] Validate Step 015 Loss 1.297 Acc 0.613\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 1.314 Acc 0.608\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3 ModuleList API\n",
    "In this part, you have to complete the implentation of CNN with ModuleList API and Module API.\n",
    "The network should have the following architectures.\n",
    "1. A convolution layer with 16 3\\*3 filters, with stride 2\n",
    "2. ReLU\n",
    "3. A convolution layer with 32 3\\*3 filters, with stride 2\n",
    "4. ReLU\n",
    "5. Flatten\n",
    "6. A fully-connected layer produce tensor to 200 \n",
    "7. ReLU\n",
    "8. A fully-connected layer produce score to 10 (classes)\n",
    "![](./resource/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"338pt\" height=\"537pt\"\n",
       " viewBox=\"0.00 0.00 338.00 537.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 533)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-533 334,-533 334,4 -4,4\"/>\n",
       "<!-- 140472681210824 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140472681210824</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"284.5,-21 199.5,-21 199.5,0 284.5,0 284.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"242\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140471981466176 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140471981466176</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"238,-78 144,-78 144,-57 238,-57 238,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981466176&#45;&gt;140472681210824 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140471981466176&#45;&gt;140472681210824</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M200.5927,-56.7787C207.6449,-48.8969 217.3997,-37.9944 225.6699,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.3907,-30.9594 232.4503,-21.1732 223.174,-26.2918 228.3907,-30.9594\"/>\n",
       "</g>\n",
       "<!-- 140471981205768 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140471981205768</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"233.5,-141.5 148.5,-141.5 148.5,-120.5 233.5,-120.5 233.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140471981205768&#45;&gt;140471981466176 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140471981205768&#45;&gt;140471981466176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191,-120.2281C191,-111.5091 191,-98.9699 191,-88.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.5001,-88.1128 191,-78.1128 187.5001,-88.1129 194.5001,-88.1128\"/>\n",
       "</g>\n",
       "<!-- 140471981205880 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140471981205880</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"192.5,-205 79.5,-205 79.5,-184 192.5,-184 192.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140471981205880&#45;&gt;140471981205768 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140471981205880&#45;&gt;140471981205768</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M145.33,-183.7281C153.4383,-174.3667 165.3611,-160.6012 174.9914,-149.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"177.9063,-151.4632 181.8078,-141.6128 172.6151,-146.8802 177.9063,-151.4632\"/>\n",
       "</g>\n",
       "<!-- 140471981206048 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140471981206048</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"183,-268.5 89,-268.5 89,-247.5 183,-247.5 183,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981206048&#45;&gt;140471981205880 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140471981206048&#45;&gt;140471981205880</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136,-247.2281C136,-238.5091 136,-225.9699 136,-215.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.5001,-215.1128 136,-205.1128 132.5001,-215.1129 139.5001,-215.1128\"/>\n",
       "</g>\n",
       "<!-- 140471981206160 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140471981206160</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"217,-332 55,-332 55,-311 217,-311 217,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"136\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140471981206160&#45;&gt;140471981206048 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140471981206160&#45;&gt;140471981206048</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M136,-310.7281C136,-302.0091 136,-289.4699 136,-278.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.5001,-278.6128 136,-268.6128 132.5001,-278.6129 139.5001,-278.6128\"/>\n",
       "</g>\n",
       "<!-- 140471981206272 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140471981206272</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-395.5 34,-395.5 34,-374.5 128,-374.5 128,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140471981206272&#45;&gt;140471981206160 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140471981206272&#45;&gt;140471981206160</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.33,-374.2281C98.4383,-364.8667 110.3611,-351.1012 119.9914,-339.9826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.9063,-341.9632 126.8078,-332.1128 117.6151,-337.3802 122.9063,-341.9632\"/>\n",
       "</g>\n",
       "<!-- 140471981206440 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140471981206440</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-459 0,-459 0,-438 162,-438 162,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140471981206440&#45;&gt;140471981206272 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140471981206440&#45;&gt;140471981206272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-437.7281C81,-429.0091 81,-416.4699 81,-405.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-405.6128 81,-395.6128 77.5001,-405.6129 84.5001,-405.6128\"/>\n",
       "</g>\n",
       "<!-- 140471981206552 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140471981206552</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"125.5,-529 36.5,-529 36.5,-495 125.5,-495 125.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">convs.0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140471981206552&#45;&gt;140471981206440 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140471981206552&#45;&gt;140471981206440</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-494.9832C81,-487.1157 81,-477.6973 81,-469.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-469.3686 81,-459.3687 77.5001,-469.3687 84.5001,-469.3686\"/>\n",
       "</g>\n",
       "<!-- 140471981206328 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140471981206328</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"235.5,-402 146.5,-402 146.5,-368 235.5,-368 235.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">convs.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140471981206328&#45;&gt;140471981206160 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140471981206328&#45;&gt;140471981206160</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M176.261,-367.9832C168.8341,-359.4085 159.8116,-348.9916 152.1918,-340.1942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.6065,-337.6361 145.4138,-332.3687 149.3153,-342.219 154.6065,-337.6361\"/>\n",
       "</g>\n",
       "<!-- 140471981205936 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140471981205936</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"283.5,-205 210.5,-205 210.5,-184 283.5,-184 283.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140471981205936&#45;&gt;140471981205768 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140471981205936&#45;&gt;140471981205768</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M237.5004,-183.7281C229.1637,-174.2749 216.8666,-160.3309 207.0119,-149.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.5987,-146.7979 200.3593,-141.6128 204.3486,-151.428 209.5987,-146.7979\"/>\n",
       "</g>\n",
       "<!-- 140471981206104 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140471981206104</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"284.5,-275 209.5,-275 209.5,-241 284.5,-241 284.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fcs.0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (200, 1568)</text>\n",
       "</g>\n",
       "<!-- 140471981206104&#45;&gt;140471981205936 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140471981206104&#45;&gt;140471981205936</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247,-240.9832C247,-233.1157 247,-223.6973 247,-215.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"250.5001,-215.3686 247,-205.3687 243.5001,-215.3687 250.5001,-215.3686\"/>\n",
       "</g>\n",
       "<!-- 140471981467128 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140471981467128</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"329.5,-78 256.5,-78 256.5,-57 329.5,-57 329.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"293\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140471981467128&#45;&gt;140472681210824 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140471981467128&#45;&gt;140472681210824</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M283.4073,-56.7787C276.3551,-48.8969 266.6003,-37.9944 258.3301,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.826,-26.2918 251.5497,-21.1732 255.6093,-30.9594 260.826,-26.2918\"/>\n",
       "</g>\n",
       "<!-- 140471981205824 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140471981205824</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"330,-148 256,-148 256,-114 330,-114 330,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"293\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fcs.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"293\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 200)</text>\n",
       "</g>\n",
       "<!-- 140471981205824&#45;&gt;140471981467128 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140471981205824&#45;&gt;140471981467128</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M293,-113.9832C293,-106.1157 293,-96.6973 293,-88.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-88.3686 293,-78.3687 289.5001,-88.3687 296.5001,-88.3686\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc25803d898>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ML(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs, self.fcs = nn.ModuleList(), nn.ModuleList()\n",
    "        ###############################################################################\n",
    "        #       TODO : Set up the layer that you need to construct the model          #\n",
    "        ###############################################################################\n",
    "        \n",
    "        self.convs.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0))\n",
    "        self.convs.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0))\n",
    "        self.fcs.append(nn.Linear(1568, 200, bias=0))\n",
    "        self.fcs.append(nn.Linear(200, 10, bias=0))\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ############################################################################### \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        ###############################################################################\n",
    "        #            TODO : Implement the forward function. You should use            #\n",
    "        #                   the layers you defined in __init__ and specify the        #\n",
    "        #                   connectivity of those layers in forward()                 #\n",
    "        ###############################################################################          \n",
    "\n",
    "        for i in range(2):\n",
    "            x = F.relu(self.convs[i](x))\n",
    "        \n",
    "        x = flatten(x)\n",
    "        x = F.relu(self.fcs[0](x))\n",
    "        out = self.fcs[1](x)\n",
    "        \n",
    "        ###############################################################################\n",
    "        #                            END TO DO                                        #\n",
    "        ###############################################################################             \n",
    "        return out\n",
    "    \n",
    "model = ML()\n",
    "x = torch.zeros((BATCH_SIZE, 3, 32, 32))\n",
    "make_dot(model(x), params=dict(model.named_parameters())) # You can check if the picture is the same \n",
    "                                                          # as previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Train the model and check the accuracy of training dataset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.300 Acc 0.156\n",
      "[  1/25] Training Step 100 Loss 2.196 Acc 0.141\n",
      "[  1/25] Training Step 200 Loss 2.220 Acc 0.141\n",
      "[  1/25] Training Step 300 Loss 2.042 Acc 0.297\n",
      "[  1/25] Training Step 400 Loss 2.041 Acc 0.266\n",
      "[  1/25] Training Step 500 Loss 1.878 Acc 0.328\n",
      "[  1/25] Training Step 600 Loss 1.869 Acc 0.344\n",
      "[  1/25] Training Step 700 Loss 1.876 Acc 0.328\n",
      "[  1/25] Validate Step 015 Loss 1.843 Acc 0.330\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 1.868 Acc 0.297\n",
      "[  2/25] Training Step 100 Loss 1.778 Acc 0.469\n",
      "[  2/25] Training Step 200 Loss 1.818 Acc 0.359\n",
      "[  2/25] Training Step 300 Loss 1.659 Acc 0.453\n",
      "[  2/25] Training Step 400 Loss 1.446 Acc 0.422\n",
      "[  2/25] Training Step 500 Loss 1.641 Acc 0.406\n",
      "[  2/25] Training Step 600 Loss 1.384 Acc 0.516\n",
      "[  2/25] Training Step 700 Loss 1.758 Acc 0.359\n",
      "[  2/25] Validate Step 015 Loss 1.665 Acc 0.410\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.798 Acc 0.297\n",
      "[  3/25] Training Step 100 Loss 1.652 Acc 0.453\n",
      "[  3/25] Training Step 200 Loss 1.497 Acc 0.438\n",
      "[  3/25] Training Step 300 Loss 1.624 Acc 0.438\n",
      "[  3/25] Training Step 400 Loss 1.965 Acc 0.312\n",
      "[  3/25] Training Step 500 Loss 1.508 Acc 0.406\n",
      "[  3/25] Training Step 600 Loss 1.657 Acc 0.359\n",
      "[  3/25] Training Step 700 Loss 1.311 Acc 0.547\n",
      "[  3/25] Validate Step 015 Loss 1.544 Acc 0.459\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.313 Acc 0.562\n",
      "[  4/25] Training Step 100 Loss 1.586 Acc 0.438\n",
      "[  4/25] Training Step 200 Loss 1.705 Acc 0.359\n",
      "[  4/25] Training Step 300 Loss 1.472 Acc 0.531\n",
      "[  4/25] Training Step 400 Loss 1.434 Acc 0.500\n",
      "[  4/25] Training Step 500 Loss 1.463 Acc 0.422\n",
      "[  4/25] Training Step 600 Loss 1.353 Acc 0.547\n",
      "[  4/25] Training Step 700 Loss 1.413 Acc 0.516\n",
      "[  4/25] Validate Step 015 Loss 1.450 Acc 0.486\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.691 Acc 0.391\n",
      "[  5/25] Training Step 100 Loss 1.403 Acc 0.453\n",
      "[  5/25] Training Step 200 Loss 1.284 Acc 0.531\n",
      "[  5/25] Training Step 300 Loss 1.339 Acc 0.531\n",
      "[  5/25] Training Step 400 Loss 1.377 Acc 0.547\n",
      "[  5/25] Training Step 500 Loss 1.222 Acc 0.562\n",
      "[  5/25] Training Step 600 Loss 1.455 Acc 0.516\n",
      "[  5/25] Training Step 700 Loss 1.234 Acc 0.531\n",
      "[  5/25] Validate Step 015 Loss 1.412 Acc 0.525\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.397 Acc 0.547\n",
      "[  6/25] Training Step 100 Loss 1.247 Acc 0.500\n",
      "[  6/25] Training Step 200 Loss 1.426 Acc 0.406\n",
      "[  6/25] Training Step 300 Loss 1.283 Acc 0.625\n",
      "[  6/25] Training Step 400 Loss 1.175 Acc 0.594\n",
      "[  6/25] Training Step 500 Loss 1.163 Acc 0.578\n",
      "[  6/25] Training Step 600 Loss 1.281 Acc 0.562\n",
      "[  6/25] Training Step 700 Loss 1.150 Acc 0.641\n",
      "[  6/25] Validate Step 015 Loss 1.330 Acc 0.544\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.222 Acc 0.594\n",
      "[  7/25] Training Step 100 Loss 1.107 Acc 0.625\n",
      "[  7/25] Training Step 200 Loss 1.428 Acc 0.438\n",
      "[  7/25] Training Step 300 Loss 1.148 Acc 0.516\n",
      "[  7/25] Training Step 400 Loss 1.246 Acc 0.578\n",
      "[  7/25] Training Step 500 Loss 1.199 Acc 0.547\n",
      "[  7/25] Training Step 600 Loss 1.310 Acc 0.500\n",
      "[  7/25] Training Step 700 Loss 1.325 Acc 0.562\n",
      "[  7/25] Validate Step 015 Loss 1.274 Acc 0.559\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 1.366 Acc 0.641\n",
      "[  8/25] Training Step 100 Loss 1.159 Acc 0.547\n",
      "[  8/25] Training Step 200 Loss 1.125 Acc 0.562\n",
      "[  8/25] Training Step 300 Loss 1.023 Acc 0.641\n",
      "[  8/25] Training Step 400 Loss 1.364 Acc 0.484\n",
      "[  8/25] Training Step 500 Loss 1.358 Acc 0.578\n",
      "[  8/25] Training Step 600 Loss 1.383 Acc 0.531\n",
      "[  8/25] Training Step 700 Loss 1.163 Acc 0.578\n",
      "[  8/25] Validate Step 015 Loss 1.234 Acc 0.554\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 1.356 Acc 0.516\n",
      "[  9/25] Training Step 100 Loss 1.159 Acc 0.578\n",
      "[  9/25] Training Step 200 Loss 1.263 Acc 0.531\n",
      "[  9/25] Training Step 300 Loss 1.188 Acc 0.547\n",
      "[  9/25] Training Step 400 Loss 1.035 Acc 0.594\n",
      "[  9/25] Training Step 500 Loss 1.337 Acc 0.578\n",
      "[  9/25] Training Step 600 Loss 1.143 Acc 0.594\n",
      "[  9/25] Training Step 700 Loss 0.879 Acc 0.719\n",
      "[  9/25] Validate Step 015 Loss 1.199 Acc 0.573\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 1.096 Acc 0.656\n",
      "[ 10/25] Training Step 100 Loss 1.042 Acc 0.625\n",
      "[ 10/25] Training Step 200 Loss 1.002 Acc 0.641\n",
      "[ 10/25] Training Step 300 Loss 0.982 Acc 0.719\n",
      "[ 10/25] Training Step 400 Loss 1.037 Acc 0.609\n",
      "[ 10/25] Training Step 500 Loss 1.209 Acc 0.734\n",
      "[ 10/25] Training Step 600 Loss 1.208 Acc 0.578\n",
      "[ 10/25] Training Step 700 Loss 1.048 Acc 0.625\n",
      "[ 10/25] Validate Step 015 Loss 1.206 Acc 0.578\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 1.211 Acc 0.625\n",
      "[ 11/25] Training Step 100 Loss 1.124 Acc 0.688\n",
      "[ 11/25] Training Step 200 Loss 1.142 Acc 0.562\n",
      "[ 11/25] Training Step 300 Loss 0.944 Acc 0.672\n",
      "[ 11/25] Training Step 400 Loss 1.036 Acc 0.672\n",
      "[ 11/25] Training Step 500 Loss 1.124 Acc 0.641\n",
      "[ 11/25] Training Step 600 Loss 1.012 Acc 0.641\n",
      "[ 11/25] Training Step 700 Loss 0.942 Acc 0.578\n",
      "[ 11/25] Validate Step 015 Loss 1.168 Acc 0.594\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 0.880 Acc 0.734\n",
      "[ 12/25] Training Step 100 Loss 1.267 Acc 0.531\n",
      "[ 12/25] Training Step 200 Loss 1.214 Acc 0.562\n",
      "[ 12/25] Training Step 300 Loss 0.943 Acc 0.641\n",
      "[ 12/25] Training Step 400 Loss 1.208 Acc 0.547\n",
      "[ 12/25] Training Step 500 Loss 0.923 Acc 0.656\n",
      "[ 12/25] Training Step 600 Loss 1.192 Acc 0.531\n",
      "[ 12/25] Training Step 700 Loss 1.170 Acc 0.500\n",
      "[ 12/25] Validate Step 015 Loss 1.173 Acc 0.585\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.983 Acc 0.688\n",
      "[ 13/25] Training Step 100 Loss 1.124 Acc 0.641\n",
      "[ 13/25] Training Step 200 Loss 1.052 Acc 0.656\n",
      "[ 13/25] Training Step 300 Loss 1.179 Acc 0.625\n",
      "[ 13/25] Training Step 400 Loss 0.815 Acc 0.703\n",
      "[ 13/25] Training Step 500 Loss 1.007 Acc 0.688\n",
      "[ 13/25] Training Step 600 Loss 1.117 Acc 0.656\n",
      "[ 13/25] Training Step 700 Loss 1.011 Acc 0.703\n",
      "[ 13/25] Validate Step 015 Loss 1.147 Acc 0.580\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 1.168 Acc 0.578\n",
      "[ 14/25] Training Step 100 Loss 1.032 Acc 0.625\n",
      "[ 14/25] Training Step 200 Loss 0.852 Acc 0.719\n",
      "[ 14/25] Training Step 300 Loss 0.920 Acc 0.719\n",
      "[ 14/25] Training Step 400 Loss 1.116 Acc 0.578\n",
      "[ 14/25] Training Step 500 Loss 0.849 Acc 0.688\n",
      "[ 14/25] Training Step 600 Loss 0.887 Acc 0.703\n",
      "[ 14/25] Training Step 700 Loss 1.099 Acc 0.656\n",
      "[ 14/25] Validate Step 015 Loss 1.112 Acc 0.595\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.915 Acc 0.656\n",
      "[ 15/25] Training Step 100 Loss 0.996 Acc 0.641\n",
      "[ 15/25] Training Step 200 Loss 0.778 Acc 0.719\n",
      "[ 15/25] Training Step 300 Loss 1.026 Acc 0.625\n",
      "[ 15/25] Training Step 400 Loss 0.864 Acc 0.672\n",
      "[ 15/25] Training Step 500 Loss 0.950 Acc 0.656\n",
      "[ 15/25] Training Step 600 Loss 0.717 Acc 0.812\n",
      "[ 15/25] Training Step 700 Loss 0.811 Acc 0.719\n",
      "[ 15/25] Validate Step 015 Loss 1.127 Acc 0.609\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.753 Acc 0.750\n",
      "[ 16/25] Training Step 100 Loss 1.027 Acc 0.641\n",
      "[ 16/25] Training Step 200 Loss 1.120 Acc 0.594\n",
      "[ 16/25] Training Step 300 Loss 1.010 Acc 0.656\n",
      "[ 16/25] Training Step 400 Loss 0.806 Acc 0.625\n",
      "[ 16/25] Training Step 500 Loss 0.989 Acc 0.703\n",
      "[ 16/25] Training Step 600 Loss 0.823 Acc 0.703\n",
      "[ 16/25] Training Step 700 Loss 0.895 Acc 0.766\n",
      "[ 16/25] Validate Step 015 Loss 1.122 Acc 0.611\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.750 Acc 0.750\n",
      "[ 17/25] Training Step 100 Loss 0.738 Acc 0.781\n",
      "[ 17/25] Training Step 200 Loss 0.832 Acc 0.703\n",
      "[ 17/25] Training Step 300 Loss 0.769 Acc 0.734\n",
      "[ 17/25] Training Step 400 Loss 0.845 Acc 0.766\n",
      "[ 17/25] Training Step 500 Loss 0.767 Acc 0.750\n",
      "[ 17/25] Training Step 600 Loss 0.842 Acc 0.656\n",
      "[ 17/25] Training Step 700 Loss 0.706 Acc 0.797\n",
      "[ 17/25] Validate Step 015 Loss 1.144 Acc 0.613\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 0.818 Acc 0.719\n",
      "[ 18/25] Training Step 100 Loss 0.712 Acc 0.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.774 Acc 0.797\n",
      "[ 18/25] Training Step 300 Loss 0.852 Acc 0.641\n",
      "[ 18/25] Training Step 400 Loss 0.878 Acc 0.672\n",
      "[ 18/25] Training Step 500 Loss 0.845 Acc 0.656\n",
      "[ 18/25] Training Step 600 Loss 0.892 Acc 0.656\n",
      "[ 18/25] Training Step 700 Loss 0.932 Acc 0.625\n",
      "[ 18/25] Validate Step 015 Loss 1.155 Acc 0.620\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.594 Acc 0.750\n",
      "[ 19/25] Training Step 100 Loss 0.769 Acc 0.703\n",
      "[ 19/25] Training Step 200 Loss 0.831 Acc 0.734\n",
      "[ 19/25] Training Step 300 Loss 0.693 Acc 0.797\n",
      "[ 19/25] Training Step 400 Loss 0.985 Acc 0.641\n",
      "[ 19/25] Training Step 500 Loss 0.851 Acc 0.719\n",
      "[ 19/25] Training Step 600 Loss 0.699 Acc 0.750\n",
      "[ 19/25] Training Step 700 Loss 0.814 Acc 0.656\n",
      "[ 19/25] Validate Step 015 Loss 1.145 Acc 0.616\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.658 Acc 0.812\n",
      "[ 20/25] Training Step 100 Loss 0.618 Acc 0.781\n",
      "[ 20/25] Training Step 200 Loss 0.575 Acc 0.766\n",
      "[ 20/25] Training Step 300 Loss 0.511 Acc 0.828\n",
      "[ 20/25] Training Step 400 Loss 0.704 Acc 0.734\n",
      "[ 20/25] Training Step 500 Loss 0.763 Acc 0.734\n",
      "[ 20/25] Training Step 600 Loss 0.726 Acc 0.781\n",
      "[ 20/25] Training Step 700 Loss 0.869 Acc 0.688\n",
      "[ 20/25] Validate Step 015 Loss 1.160 Acc 0.605\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.565 Acc 0.797\n",
      "[ 21/25] Training Step 100 Loss 0.704 Acc 0.781\n",
      "[ 21/25] Training Step 200 Loss 0.642 Acc 0.797\n",
      "[ 21/25] Training Step 300 Loss 0.493 Acc 0.875\n",
      "[ 21/25] Training Step 400 Loss 0.768 Acc 0.781\n",
      "[ 21/25] Training Step 500 Loss 0.817 Acc 0.688\n",
      "[ 21/25] Training Step 600 Loss 0.859 Acc 0.594\n",
      "[ 21/25] Training Step 700 Loss 0.742 Acc 0.750\n",
      "[ 21/25] Validate Step 015 Loss 1.213 Acc 0.618\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.603 Acc 0.750\n",
      "[ 22/25] Training Step 100 Loss 0.624 Acc 0.828\n",
      "[ 22/25] Training Step 200 Loss 0.827 Acc 0.719\n",
      "[ 22/25] Training Step 300 Loss 0.475 Acc 0.812\n",
      "[ 22/25] Training Step 400 Loss 0.760 Acc 0.734\n",
      "[ 22/25] Training Step 500 Loss 0.737 Acc 0.797\n",
      "[ 22/25] Training Step 600 Loss 0.586 Acc 0.797\n",
      "[ 22/25] Training Step 700 Loss 0.629 Acc 0.797\n",
      "[ 22/25] Validate Step 015 Loss 1.272 Acc 0.608\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.624 Acc 0.797\n",
      "[ 23/25] Training Step 100 Loss 0.543 Acc 0.844\n",
      "[ 23/25] Training Step 200 Loss 0.496 Acc 0.797\n",
      "[ 23/25] Training Step 300 Loss 0.642 Acc 0.781\n",
      "[ 23/25] Training Step 400 Loss 0.701 Acc 0.797\n",
      "[ 23/25] Training Step 500 Loss 0.561 Acc 0.766\n",
      "[ 23/25] Training Step 600 Loss 0.466 Acc 0.828\n",
      "[ 23/25] Training Step 700 Loss 0.531 Acc 0.828\n",
      "[ 23/25] Validate Step 015 Loss 1.272 Acc 0.606\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.659 Acc 0.750\n",
      "[ 24/25] Training Step 100 Loss 0.469 Acc 0.844\n",
      "[ 24/25] Training Step 200 Loss 0.391 Acc 0.844\n",
      "[ 24/25] Training Step 300 Loss 0.336 Acc 0.844\n",
      "[ 24/25] Training Step 400 Loss 0.608 Acc 0.812\n",
      "[ 24/25] Training Step 500 Loss 0.524 Acc 0.844\n",
      "[ 24/25] Training Step 600 Loss 0.451 Acc 0.828\n",
      "[ 24/25] Training Step 700 Loss 0.537 Acc 0.812\n",
      "[ 24/25] Validate Step 015 Loss 1.271 Acc 0.626\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.360 Acc 0.859\n",
      "[ 25/25] Training Step 100 Loss 0.255 Acc 0.938\n",
      "[ 25/25] Training Step 200 Loss 0.539 Acc 0.828\n",
      "[ 25/25] Training Step 300 Loss 0.393 Acc 0.844\n",
      "[ 25/25] Training Step 400 Loss 0.358 Acc 0.875\n",
      "[ 25/25] Training Step 500 Loss 0.781 Acc 0.812\n",
      "[ 25/25] Training Step 600 Loss 0.743 Acc 0.812\n",
      "[ 25/25] Training Step 700 Loss 0.733 Acc 0.703\n",
      "[ 25/25] Validate Step 015 Loss 1.371 Acc 0.614\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 1.401 Acc 0.595\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4 Sequential\n",
    "In this part, you have to complete the implentation of CNN with Sequential API.\n",
    "The network should have the following architectures.\n",
    "1. A convolution layer with 16 3\\*3 filters, with stride 2\n",
    "2. ReLU\n",
    "3. A convolution layer with 32 3\\*3 filters, with stride 2\n",
    "4. ReLU\n",
    "5. Flatten\n",
    "6. A fully-connected layer produce tensor to 200 \n",
    "7. ReLU\n",
    "8. A fully-connected layer produce score to 10 (classes)\n",
    "![](./resource/model_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"336pt\" height=\"537pt\"\n",
       " viewBox=\"0.00 0.00 335.50 537.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 533)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-533 331.5,-533 331.5,4 -4,4\"/>\n",
       "<!-- 140472675899320 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140472675899320</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"282.5,-21 197.5,-21 197.5,0 282.5,0 282.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140472675898200 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140472675898200</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"236,-78 142,-78 142,-57 236,-57 236,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140472675898200&#45;&gt;140472675899320 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140472675898200&#45;&gt;140472675899320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.5927,-56.7787C205.6449,-48.8969 215.3997,-37.9944 223.6699,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.3907,-30.9594 230.4503,-21.1732 221.174,-26.2918 226.3907,-30.9594\"/>\n",
       "</g>\n",
       "<!-- 140472675898704 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140472675898704</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"231.5,-141.5 146.5,-141.5 146.5,-120.5 231.5,-120.5 231.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140472675898704&#45;&gt;140472675898200 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140472675898704&#45;&gt;140472675898200</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M189,-120.2281C189,-111.5091 189,-98.9699 189,-88.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.5001,-88.1128 189,-78.1128 185.5001,-88.1129 192.5001,-88.1128\"/>\n",
       "</g>\n",
       "<!-- 140472675901392 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140472675901392</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"190.5,-205 77.5,-205 77.5,-184 190.5,-184 190.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140472675901392&#45;&gt;140472675898704 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140472675901392&#45;&gt;140472675898704</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.33,-183.7281C151.4383,-174.3667 163.3611,-160.6012 172.9914,-149.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"175.9063,-151.4632 179.8078,-141.6128 170.6151,-146.8802 175.9063,-151.4632\"/>\n",
       "</g>\n",
       "<!-- 140472675901056 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140472675901056</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"181,-268.5 87,-268.5 87,-247.5 181,-247.5 181,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140472675901056&#45;&gt;140472675901392 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140472675901056&#45;&gt;140472675901392</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-247.2281C134,-238.5091 134,-225.9699 134,-215.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-215.1128 134,-205.1128 130.5001,-215.1129 137.5001,-215.1128\"/>\n",
       "</g>\n",
       "<!-- 140472675901224 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140472675901224</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"215,-332 53,-332 53,-311 215,-311 215,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"134\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140472675901224&#45;&gt;140472675901056 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140472675901224&#45;&gt;140472675901056</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-310.7281C134,-302.0091 134,-289.4699 134,-278.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-278.6128 134,-268.6128 130.5001,-278.6129 137.5001,-278.6128\"/>\n",
       "</g>\n",
       "<!-- 140472675901000 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140472675901000</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-395.5 34,-395.5 34,-374.5 128,-374.5 128,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140472675901000&#45;&gt;140472675901224 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140472675901000&#45;&gt;140472675901224</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M89.9907,-374.2281C97.8042,-364.8667 109.2935,-351.1012 118.5736,-339.9826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.4213,-342.0328 125.1421,-332.1128 116.0472,-337.5474 121.4213,-342.0328\"/>\n",
       "</g>\n",
       "<!-- 140472676159616 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140472676159616</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-459 0,-459 0,-438 162,-438 162,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140472676159616&#45;&gt;140472675901000 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140472676159616&#45;&gt;140472675901000</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-437.7281C81,-429.0091 81,-416.4699 81,-405.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-405.6128 81,-395.6128 77.5001,-405.6129 84.5001,-405.6128\"/>\n",
       "</g>\n",
       "<!-- 140472676162472 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140472676162472</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"121.5,-529 40.5,-529 40.5,-495 121.5,-495 121.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"81\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140472676162472&#45;&gt;140472676159616 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140472676162472&#45;&gt;140472676159616</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M81,-494.9832C81,-487.1157 81,-477.6973 81,-469.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-469.3686 81,-459.3687 77.5001,-469.3687 84.5001,-469.3686\"/>\n",
       "</g>\n",
       "<!-- 140474679405984 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140474679405984</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"227.5,-402 146.5,-402 146.5,-368 227.5,-368 227.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"187\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140474679405984&#45;&gt;140472675901224 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140474679405984&#45;&gt;140472675901224</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.797,-367.9832C165.6401,-359.4085 156.9458,-348.9916 149.603,-340.1942\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.1664,-337.8032 143.0715,-332.3687 146.7923,-342.2887 152.1664,-337.8032\"/>\n",
       "</g>\n",
       "<!-- 140472675901336 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140472675901336</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"281.5,-205 208.5,-205 208.5,-184 281.5,-184 281.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140472675901336&#45;&gt;140472675898704 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140472675901336&#45;&gt;140472675898704</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.5004,-183.7281C227.1637,-174.2749 214.8666,-160.3309 205.0119,-149.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"207.5987,-146.7979 198.3593,-141.6128 202.3486,-151.428 207.5987,-146.7979\"/>\n",
       "</g>\n",
       "<!-- 140472675901280 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140472675901280</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"282.5,-275 207.5,-275 207.5,-241 282.5,-241 282.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (200, 1568)</text>\n",
       "</g>\n",
       "<!-- 140472675901280&#45;&gt;140472675901336 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140472675901280&#45;&gt;140472675901336</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245,-240.9832C245,-233.1157 245,-223.6973 245,-215.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.5001,-215.3686 245,-205.3687 241.5001,-215.3687 248.5001,-215.3686\"/>\n",
       "</g>\n",
       "<!-- 140472675899208 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140472675899208</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"327.5,-78 254.5,-78 254.5,-57 327.5,-57 327.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140472675899208&#45;&gt;140472675899320 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140472675899208&#45;&gt;140472675899320</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.4073,-56.7787C274.3551,-48.8969 264.6003,-37.9944 256.3301,-28.7512\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"258.826,-26.2918 249.5497,-21.1732 253.6093,-30.9594 258.826,-26.2918\"/>\n",
       "</g>\n",
       "<!-- 140472675898312 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140472675898312</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"324.5,-148 257.5,-148 257.5,-114 324.5,-114 324.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"291\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 200)</text>\n",
       "</g>\n",
       "<!-- 140472675898312&#45;&gt;140472675899208 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140472675898312&#45;&gt;140472675899208</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291,-113.9832C291,-106.1157 291,-96.6973 291,-88.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.5001,-88.3686 291,-78.3687 287.5001,-88.3687 294.5001,-88.3686\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc257f296d8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = None\n",
    "###############################################################################\n",
    "#            TODO : Implement the Sequential API to complete the model        #\n",
    "###############################################################################          \n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('flatten', Flatten()),\n",
    "    ('fc1', nn.Linear(1568, 200, bias=0)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(200, 10, bias=0))\n",
    "    ]))\n",
    "\n",
    "###############################################################################\n",
    "#                            END TO DO                                        #\n",
    "###############################################################################  \n",
    "x = torch.zeros((BATCH_SIZE, 3, 32, 32))\n",
    "make_dot(model(x), params=dict(model.named_parameters())) # You can check if the picture is the same \n",
    "                                                          # as previous picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Train the model and check the accuracy of training dataset and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.303 Acc 0.141\n",
      "[  1/25] Training Step 100 Loss 2.291 Acc 0.172\n",
      "[  1/25] Training Step 200 Loss 2.262 Acc 0.250\n",
      "[  1/25] Training Step 300 Loss 2.171 Acc 0.328\n",
      "[  1/25] Training Step 400 Loss 2.079 Acc 0.281\n",
      "[  1/25] Training Step 500 Loss 1.974 Acc 0.266\n",
      "[  1/25] Training Step 600 Loss 2.082 Acc 0.266\n",
      "[  1/25] Training Step 700 Loss 1.987 Acc 0.297\n",
      "[  1/25] Validate Step 015 Loss 1.898 Acc 0.342\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 1.807 Acc 0.375\n",
      "[  2/25] Training Step 100 Loss 1.864 Acc 0.328\n",
      "[  2/25] Training Step 200 Loss 1.657 Acc 0.297\n",
      "[  2/25] Training Step 300 Loss 1.783 Acc 0.359\n",
      "[  2/25] Training Step 400 Loss 1.751 Acc 0.422\n",
      "[  2/25] Training Step 500 Loss 1.750 Acc 0.375\n",
      "[  2/25] Training Step 600 Loss 1.723 Acc 0.406\n",
      "[  2/25] Training Step 700 Loss 1.709 Acc 0.312\n",
      "[  2/25] Validate Step 015 Loss 1.684 Acc 0.419\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.676 Acc 0.453\n",
      "[  3/25] Training Step 100 Loss 1.605 Acc 0.406\n",
      "[  3/25] Training Step 200 Loss 1.571 Acc 0.484\n",
      "[  3/25] Training Step 300 Loss 1.753 Acc 0.328\n",
      "[  3/25] Training Step 400 Loss 1.490 Acc 0.500\n",
      "[  3/25] Training Step 500 Loss 1.518 Acc 0.438\n",
      "[  3/25] Training Step 600 Loss 1.502 Acc 0.500\n",
      "[  3/25] Training Step 700 Loss 1.434 Acc 0.484\n",
      "[  3/25] Validate Step 015 Loss 1.520 Acc 0.463\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.594 Acc 0.469\n",
      "[  4/25] Training Step 100 Loss 1.495 Acc 0.484\n",
      "[  4/25] Training Step 200 Loss 1.448 Acc 0.469\n",
      "[  4/25] Training Step 300 Loss 1.534 Acc 0.375\n",
      "[  4/25] Training Step 400 Loss 1.315 Acc 0.547\n",
      "[  4/25] Training Step 500 Loss 1.493 Acc 0.453\n",
      "[  4/25] Training Step 600 Loss 1.344 Acc 0.469\n",
      "[  4/25] Training Step 700 Loss 1.314 Acc 0.562\n",
      "[  4/25] Validate Step 015 Loss 1.378 Acc 0.515\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.396 Acc 0.484\n",
      "[  5/25] Training Step 100 Loss 1.563 Acc 0.547\n",
      "[  5/25] Training Step 200 Loss 1.413 Acc 0.578\n",
      "[  5/25] Training Step 300 Loss 1.313 Acc 0.484\n",
      "[  5/25] Training Step 400 Loss 1.233 Acc 0.594\n",
      "[  5/25] Training Step 500 Loss 1.337 Acc 0.531\n",
      "[  5/25] Training Step 600 Loss 1.580 Acc 0.438\n",
      "[  5/25] Training Step 700 Loss 1.212 Acc 0.609\n",
      "[  5/25] Validate Step 015 Loss 1.322 Acc 0.518\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.246 Acc 0.547\n",
      "[  6/25] Training Step 100 Loss 1.335 Acc 0.469\n",
      "[  6/25] Training Step 200 Loss 1.341 Acc 0.578\n",
      "[  6/25] Training Step 300 Loss 1.296 Acc 0.547\n",
      "[  6/25] Training Step 400 Loss 1.178 Acc 0.656\n",
      "[  6/25] Training Step 500 Loss 1.289 Acc 0.484\n",
      "[  6/25] Training Step 600 Loss 1.180 Acc 0.609\n",
      "[  6/25] Training Step 700 Loss 1.140 Acc 0.578\n",
      "[  6/25] Validate Step 015 Loss 1.283 Acc 0.548\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.108 Acc 0.594\n",
      "[  7/25] Training Step 100 Loss 1.397 Acc 0.578\n",
      "[  7/25] Training Step 200 Loss 1.285 Acc 0.578\n",
      "[  7/25] Training Step 300 Loss 1.354 Acc 0.531\n",
      "[  7/25] Training Step 400 Loss 1.151 Acc 0.656\n",
      "[  7/25] Training Step 500 Loss 1.388 Acc 0.484\n",
      "[  7/25] Training Step 600 Loss 1.049 Acc 0.688\n",
      "[  7/25] Training Step 700 Loss 1.197 Acc 0.562\n",
      "[  7/25] Validate Step 015 Loss 1.244 Acc 0.570\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 1.214 Acc 0.547\n",
      "[  8/25] Training Step 100 Loss 1.151 Acc 0.625\n",
      "[  8/25] Training Step 200 Loss 1.191 Acc 0.594\n",
      "[  8/25] Training Step 300 Loss 1.621 Acc 0.438\n",
      "[  8/25] Training Step 400 Loss 0.942 Acc 0.734\n",
      "[  8/25] Training Step 500 Loss 1.195 Acc 0.594\n",
      "[  8/25] Training Step 600 Loss 1.173 Acc 0.578\n",
      "[  8/25] Training Step 700 Loss 1.130 Acc 0.562\n",
      "[  8/25] Validate Step 015 Loss 1.191 Acc 0.583\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 0.895 Acc 0.703\n",
      "[  9/25] Training Step 100 Loss 1.376 Acc 0.531\n",
      "[  9/25] Training Step 200 Loss 1.072 Acc 0.641\n",
      "[  9/25] Training Step 300 Loss 1.096 Acc 0.594\n",
      "[  9/25] Training Step 400 Loss 0.946 Acc 0.656\n",
      "[  9/25] Training Step 500 Loss 0.964 Acc 0.688\n",
      "[  9/25] Training Step 600 Loss 1.023 Acc 0.672\n",
      "[  9/25] Training Step 700 Loss 1.229 Acc 0.578\n",
      "[  9/25] Validate Step 015 Loss 1.158 Acc 0.605\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 1.113 Acc 0.578\n",
      "[ 10/25] Training Step 100 Loss 0.890 Acc 0.719\n",
      "[ 10/25] Training Step 200 Loss 1.178 Acc 0.547\n",
      "[ 10/25] Training Step 300 Loss 1.232 Acc 0.594\n",
      "[ 10/25] Training Step 400 Loss 1.087 Acc 0.641\n",
      "[ 10/25] Training Step 500 Loss 1.129 Acc 0.594\n",
      "[ 10/25] Training Step 600 Loss 1.195 Acc 0.562\n",
      "[ 10/25] Training Step 700 Loss 1.083 Acc 0.688\n",
      "[ 10/25] Validate Step 015 Loss 1.168 Acc 0.611\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 1.055 Acc 0.547\n",
      "[ 11/25] Training Step 100 Loss 1.109 Acc 0.562\n",
      "[ 11/25] Training Step 200 Loss 1.385 Acc 0.422\n",
      "[ 11/25] Training Step 300 Loss 1.201 Acc 0.594\n",
      "[ 11/25] Training Step 400 Loss 1.130 Acc 0.578\n",
      "[ 11/25] Training Step 500 Loss 0.900 Acc 0.703\n",
      "[ 11/25] Training Step 600 Loss 0.781 Acc 0.766\n",
      "[ 11/25] Training Step 700 Loss 1.237 Acc 0.562\n",
      "[ 11/25] Validate Step 015 Loss 1.113 Acc 0.622\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 0.825 Acc 0.734\n",
      "[ 12/25] Training Step 100 Loss 1.090 Acc 0.562\n",
      "[ 12/25] Training Step 200 Loss 0.953 Acc 0.766\n",
      "[ 12/25] Training Step 300 Loss 0.944 Acc 0.656\n",
      "[ 12/25] Training Step 400 Loss 0.876 Acc 0.734\n",
      "[ 12/25] Training Step 500 Loss 0.934 Acc 0.703\n",
      "[ 12/25] Training Step 600 Loss 1.054 Acc 0.609\n",
      "[ 12/25] Training Step 700 Loss 0.947 Acc 0.719\n",
      "[ 12/25] Validate Step 015 Loss 1.104 Acc 0.615\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.996 Acc 0.594\n",
      "[ 13/25] Training Step 100 Loss 0.987 Acc 0.672\n",
      "[ 13/25] Training Step 200 Loss 0.951 Acc 0.672\n",
      "[ 13/25] Training Step 300 Loss 0.811 Acc 0.750\n",
      "[ 13/25] Training Step 400 Loss 1.177 Acc 0.625\n",
      "[ 13/25] Training Step 500 Loss 0.927 Acc 0.672\n",
      "[ 13/25] Training Step 600 Loss 1.164 Acc 0.594\n",
      "[ 13/25] Training Step 700 Loss 1.123 Acc 0.641\n",
      "[ 13/25] Validate Step 015 Loss 1.085 Acc 0.609\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 0.836 Acc 0.688\n",
      "[ 14/25] Training Step 100 Loss 0.784 Acc 0.703\n",
      "[ 14/25] Training Step 200 Loss 0.921 Acc 0.672\n",
      "[ 14/25] Training Step 300 Loss 0.950 Acc 0.719\n",
      "[ 14/25] Training Step 400 Loss 0.865 Acc 0.672\n",
      "[ 14/25] Training Step 500 Loss 1.012 Acc 0.719\n",
      "[ 14/25] Training Step 600 Loss 0.904 Acc 0.719\n",
      "[ 14/25] Training Step 700 Loss 0.909 Acc 0.656\n",
      "[ 14/25] Validate Step 015 Loss 1.061 Acc 0.632\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.948 Acc 0.703\n",
      "[ 15/25] Training Step 100 Loss 0.780 Acc 0.719\n",
      "[ 15/25] Training Step 200 Loss 0.853 Acc 0.688\n",
      "[ 15/25] Training Step 300 Loss 1.075 Acc 0.672\n",
      "[ 15/25] Training Step 400 Loss 0.982 Acc 0.719\n",
      "[ 15/25] Training Step 500 Loss 0.930 Acc 0.641\n",
      "[ 15/25] Training Step 600 Loss 1.055 Acc 0.625\n",
      "[ 15/25] Training Step 700 Loss 0.935 Acc 0.688\n",
      "[ 15/25] Validate Step 015 Loss 1.062 Acc 0.627\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.963 Acc 0.703\n",
      "[ 16/25] Training Step 100 Loss 0.723 Acc 0.766\n",
      "[ 16/25] Training Step 200 Loss 0.775 Acc 0.734\n",
      "[ 16/25] Training Step 300 Loss 0.753 Acc 0.734\n",
      "[ 16/25] Training Step 400 Loss 1.060 Acc 0.562\n",
      "[ 16/25] Training Step 500 Loss 0.745 Acc 0.719\n",
      "[ 16/25] Training Step 600 Loss 0.803 Acc 0.766\n",
      "[ 16/25] Training Step 700 Loss 0.948 Acc 0.672\n",
      "[ 16/25] Validate Step 015 Loss 1.060 Acc 0.642\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.647 Acc 0.797\n",
      "[ 17/25] Training Step 100 Loss 0.793 Acc 0.750\n",
      "[ 17/25] Training Step 200 Loss 0.740 Acc 0.734\n",
      "[ 17/25] Training Step 300 Loss 0.806 Acc 0.688\n",
      "[ 17/25] Training Step 400 Loss 0.759 Acc 0.719\n",
      "[ 17/25] Training Step 500 Loss 0.772 Acc 0.703\n",
      "[ 17/25] Training Step 600 Loss 1.077 Acc 0.594\n",
      "[ 17/25] Training Step 700 Loss 0.714 Acc 0.688\n",
      "[ 17/25] Validate Step 015 Loss 1.074 Acc 0.637\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 0.547 Acc 0.828\n",
      "[ 18/25] Training Step 100 Loss 0.868 Acc 0.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.568 Acc 0.781\n",
      "[ 18/25] Training Step 300 Loss 1.018 Acc 0.766\n",
      "[ 18/25] Training Step 400 Loss 0.865 Acc 0.672\n",
      "[ 18/25] Training Step 500 Loss 0.672 Acc 0.750\n",
      "[ 18/25] Training Step 600 Loss 0.871 Acc 0.688\n",
      "[ 18/25] Training Step 700 Loss 0.780 Acc 0.734\n",
      "[ 18/25] Validate Step 015 Loss 1.116 Acc 0.643\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.626 Acc 0.781\n",
      "[ 19/25] Training Step 100 Loss 0.519 Acc 0.859\n",
      "[ 19/25] Training Step 200 Loss 0.750 Acc 0.719\n",
      "[ 19/25] Training Step 300 Loss 0.583 Acc 0.828\n",
      "[ 19/25] Training Step 400 Loss 0.716 Acc 0.750\n",
      "[ 19/25] Training Step 500 Loss 0.858 Acc 0.672\n",
      "[ 19/25] Training Step 600 Loss 0.874 Acc 0.734\n",
      "[ 19/25] Training Step 700 Loss 0.739 Acc 0.734\n",
      "[ 19/25] Validate Step 015 Loss 1.096 Acc 0.649\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.632 Acc 0.781\n",
      "[ 20/25] Training Step 100 Loss 0.577 Acc 0.781\n",
      "[ 20/25] Training Step 200 Loss 0.593 Acc 0.750\n",
      "[ 20/25] Training Step 300 Loss 0.894 Acc 0.766\n",
      "[ 20/25] Training Step 400 Loss 0.531 Acc 0.812\n",
      "[ 20/25] Training Step 500 Loss 0.675 Acc 0.766\n",
      "[ 20/25] Training Step 600 Loss 0.562 Acc 0.844\n",
      "[ 20/25] Training Step 700 Loss 0.744 Acc 0.719\n",
      "[ 20/25] Validate Step 015 Loss 1.102 Acc 0.659\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.615 Acc 0.734\n",
      "[ 21/25] Training Step 100 Loss 0.624 Acc 0.797\n",
      "[ 21/25] Training Step 200 Loss 0.550 Acc 0.766\n",
      "[ 21/25] Training Step 300 Loss 0.491 Acc 0.812\n",
      "[ 21/25] Training Step 400 Loss 0.696 Acc 0.828\n",
      "[ 21/25] Training Step 500 Loss 0.776 Acc 0.781\n",
      "[ 21/25] Training Step 600 Loss 0.674 Acc 0.766\n",
      "[ 21/25] Training Step 700 Loss 0.732 Acc 0.719\n",
      "[ 21/25] Validate Step 015 Loss 1.121 Acc 0.634\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.492 Acc 0.844\n",
      "[ 22/25] Training Step 100 Loss 0.646 Acc 0.812\n",
      "[ 22/25] Training Step 200 Loss 0.513 Acc 0.828\n",
      "[ 22/25] Training Step 300 Loss 0.640 Acc 0.734\n",
      "[ 22/25] Training Step 400 Loss 0.839 Acc 0.734\n",
      "[ 22/25] Training Step 500 Loss 0.553 Acc 0.812\n",
      "[ 22/25] Training Step 600 Loss 0.515 Acc 0.844\n",
      "[ 22/25] Training Step 700 Loss 0.531 Acc 0.828\n",
      "[ 22/25] Validate Step 015 Loss 1.129 Acc 0.639\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.539 Acc 0.844\n",
      "[ 23/25] Training Step 100 Loss 0.415 Acc 0.875\n",
      "[ 23/25] Training Step 200 Loss 0.595 Acc 0.766\n",
      "[ 23/25] Training Step 300 Loss 0.546 Acc 0.844\n",
      "[ 23/25] Training Step 400 Loss 0.423 Acc 0.891\n",
      "[ 23/25] Training Step 500 Loss 0.467 Acc 0.844\n",
      "[ 23/25] Training Step 600 Loss 0.495 Acc 0.875\n",
      "[ 23/25] Training Step 700 Loss 0.540 Acc 0.859\n",
      "[ 23/25] Validate Step 015 Loss 1.182 Acc 0.648\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.613 Acc 0.750\n",
      "[ 24/25] Training Step 100 Loss 0.488 Acc 0.906\n",
      "[ 24/25] Training Step 200 Loss 0.452 Acc 0.891\n",
      "[ 24/25] Training Step 300 Loss 0.424 Acc 0.844\n",
      "[ 24/25] Training Step 400 Loss 0.336 Acc 0.891\n",
      "[ 24/25] Training Step 500 Loss 0.434 Acc 0.828\n",
      "[ 24/25] Training Step 600 Loss 0.615 Acc 0.781\n",
      "[ 24/25] Training Step 700 Loss 0.468 Acc 0.859\n",
      "[ 24/25] Validate Step 015 Loss 1.178 Acc 0.642\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.480 Acc 0.844\n",
      "[ 25/25] Training Step 100 Loss 0.333 Acc 0.906\n",
      "[ 25/25] Training Step 200 Loss 0.420 Acc 0.859\n",
      "[ 25/25] Training Step 300 Loss 0.339 Acc 0.859\n",
      "[ 25/25] Training Step 400 Loss 0.349 Acc 0.875\n",
      "[ 25/25] Training Step 500 Loss 0.397 Acc 0.828\n",
      "[ 25/25] Training Step 600 Loss 0.326 Acc 0.859\n",
      "[ 25/25] Training Step 700 Loss 0.579 Acc 0.781\n",
      "[ 25/25] Validate Step 015 Loss 1.247 Acc 0.654\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 1.291 Acc 0.632\n"
     ]
    }
   ],
   "source": [
    "if CUDA:\n",
    "    model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 CIFAR-10 open-ended challenge\n",
    "In this section, you can experiment with whatever ConvNet architecture you'd like on CIFAR-10\n",
    "### Baseline : 65% on Testing data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/25] Training Step 000 Loss 2.324 Acc 0.047\n",
      "[  1/25] Training Step 100 Loss 2.099 Acc 0.266\n",
      "[  1/25] Training Step 200 Loss 1.783 Acc 0.375\n",
      "[  1/25] Training Step 300 Loss 1.839 Acc 0.344\n",
      "[  1/25] Training Step 400 Loss 1.735 Acc 0.359\n",
      "[  1/25] Training Step 500 Loss 1.540 Acc 0.516\n",
      "[  1/25] Training Step 600 Loss 1.565 Acc 0.422\n",
      "[  1/25] Training Step 700 Loss 1.594 Acc 0.484\n",
      "[  1/25] Validate Step 015 Loss 1.451 Acc 0.494\n",
      "---------------- Epoch 1 ----------------\n",
      "[  2/25] Training Step 000 Loss 1.497 Acc 0.375\n",
      "[  2/25] Training Step 100 Loss 1.218 Acc 0.516\n",
      "[  2/25] Training Step 200 Loss 1.449 Acc 0.422\n",
      "[  2/25] Training Step 300 Loss 1.400 Acc 0.469\n",
      "[  2/25] Training Step 400 Loss 1.382 Acc 0.469\n",
      "[  2/25] Training Step 500 Loss 1.360 Acc 0.500\n",
      "[  2/25] Training Step 600 Loss 1.254 Acc 0.562\n",
      "[  2/25] Training Step 700 Loss 1.296 Acc 0.562\n",
      "[  2/25] Validate Step 015 Loss 1.283 Acc 0.543\n",
      "---------------- Epoch 2 ----------------\n",
      "[  3/25] Training Step 000 Loss 1.219 Acc 0.625\n",
      "[  3/25] Training Step 100 Loss 1.553 Acc 0.438\n",
      "[  3/25] Training Step 200 Loss 1.380 Acc 0.484\n",
      "[  3/25] Training Step 300 Loss 1.130 Acc 0.594\n",
      "[  3/25] Training Step 400 Loss 1.056 Acc 0.656\n",
      "[  3/25] Training Step 500 Loss 1.258 Acc 0.578\n",
      "[  3/25] Training Step 600 Loss 1.330 Acc 0.531\n",
      "[  3/25] Training Step 700 Loss 1.221 Acc 0.562\n",
      "[  3/25] Validate Step 015 Loss 1.208 Acc 0.563\n",
      "---------------- Epoch 3 ----------------\n",
      "[  4/25] Training Step 000 Loss 1.089 Acc 0.672\n",
      "[  4/25] Training Step 100 Loss 1.187 Acc 0.562\n",
      "[  4/25] Training Step 200 Loss 1.264 Acc 0.562\n",
      "[  4/25] Training Step 300 Loss 1.258 Acc 0.547\n",
      "[  4/25] Training Step 400 Loss 0.998 Acc 0.672\n",
      "[  4/25] Training Step 500 Loss 1.229 Acc 0.609\n",
      "[  4/25] Training Step 600 Loss 0.989 Acc 0.609\n",
      "[  4/25] Training Step 700 Loss 1.265 Acc 0.531\n",
      "[  4/25] Validate Step 015 Loss 1.145 Acc 0.578\n",
      "---------------- Epoch 4 ----------------\n",
      "[  5/25] Training Step 000 Loss 1.039 Acc 0.641\n",
      "[  5/25] Training Step 100 Loss 1.031 Acc 0.672\n",
      "[  5/25] Training Step 200 Loss 1.313 Acc 0.484\n",
      "[  5/25] Training Step 300 Loss 1.063 Acc 0.578\n",
      "[  5/25] Training Step 400 Loss 0.983 Acc 0.641\n",
      "[  5/25] Training Step 500 Loss 1.069 Acc 0.609\n",
      "[  5/25] Training Step 600 Loss 1.279 Acc 0.562\n",
      "[  5/25] Training Step 700 Loss 0.964 Acc 0.672\n",
      "[  5/25] Validate Step 015 Loss 1.108 Acc 0.594\n",
      "---------------- Epoch 5 ----------------\n",
      "[  6/25] Training Step 000 Loss 1.230 Acc 0.516\n",
      "[  6/25] Training Step 100 Loss 1.222 Acc 0.625\n",
      "[  6/25] Training Step 200 Loss 1.119 Acc 0.672\n",
      "[  6/25] Training Step 300 Loss 0.981 Acc 0.672\n",
      "[  6/25] Training Step 400 Loss 0.990 Acc 0.625\n",
      "[  6/25] Training Step 500 Loss 0.825 Acc 0.688\n",
      "[  6/25] Training Step 600 Loss 1.243 Acc 0.562\n",
      "[  6/25] Training Step 700 Loss 1.024 Acc 0.656\n",
      "[  6/25] Validate Step 015 Loss 1.045 Acc 0.616\n",
      "---------------- Epoch 6 ----------------\n",
      "[  7/25] Training Step 000 Loss 1.061 Acc 0.625\n",
      "[  7/25] Training Step 100 Loss 1.059 Acc 0.609\n",
      "[  7/25] Training Step 200 Loss 0.988 Acc 0.703\n",
      "[  7/25] Training Step 300 Loss 1.077 Acc 0.625\n",
      "[  7/25] Training Step 400 Loss 0.814 Acc 0.719\n",
      "[  7/25] Training Step 500 Loss 1.178 Acc 0.547\n",
      "[  7/25] Training Step 600 Loss 1.191 Acc 0.609\n",
      "[  7/25] Training Step 700 Loss 0.969 Acc 0.641\n",
      "[  7/25] Validate Step 015 Loss 1.025 Acc 0.640\n",
      "---------------- Epoch 7 ----------------\n",
      "[  8/25] Training Step 000 Loss 0.841 Acc 0.766\n",
      "[  8/25] Training Step 100 Loss 1.015 Acc 0.672\n",
      "[  8/25] Training Step 200 Loss 0.864 Acc 0.672\n",
      "[  8/25] Training Step 300 Loss 0.795 Acc 0.688\n",
      "[  8/25] Training Step 400 Loss 1.369 Acc 0.547\n",
      "[  8/25] Training Step 500 Loss 1.006 Acc 0.641\n",
      "[  8/25] Training Step 600 Loss 0.646 Acc 0.797\n",
      "[  8/25] Training Step 700 Loss 0.776 Acc 0.781\n",
      "[  8/25] Validate Step 015 Loss 1.015 Acc 0.638\n",
      "---------------- Epoch 8 ----------------\n",
      "[  9/25] Training Step 000 Loss 0.870 Acc 0.703\n",
      "[  9/25] Training Step 100 Loss 0.992 Acc 0.609\n",
      "[  9/25] Training Step 200 Loss 0.931 Acc 0.656\n",
      "[  9/25] Training Step 300 Loss 1.007 Acc 0.625\n",
      "[  9/25] Training Step 400 Loss 0.946 Acc 0.719\n",
      "[  9/25] Training Step 500 Loss 0.967 Acc 0.672\n",
      "[  9/25] Training Step 600 Loss 1.059 Acc 0.641\n",
      "[  9/25] Training Step 700 Loss 0.864 Acc 0.703\n",
      "[  9/25] Validate Step 015 Loss 0.997 Acc 0.646\n",
      "---------------- Epoch 9 ----------------\n",
      "[ 10/25] Training Step 000 Loss 0.846 Acc 0.703\n",
      "[ 10/25] Training Step 100 Loss 0.979 Acc 0.703\n",
      "[ 10/25] Training Step 200 Loss 1.051 Acc 0.625\n",
      "[ 10/25] Training Step 300 Loss 0.953 Acc 0.688\n",
      "[ 10/25] Training Step 400 Loss 0.662 Acc 0.766\n",
      "[ 10/25] Training Step 500 Loss 1.066 Acc 0.672\n",
      "[ 10/25] Training Step 600 Loss 0.854 Acc 0.734\n",
      "[ 10/25] Training Step 700 Loss 0.749 Acc 0.734\n",
      "[ 10/25] Validate Step 015 Loss 0.971 Acc 0.658\n",
      "---------------- Epoch 10 ----------------\n",
      "[ 11/25] Training Step 000 Loss 0.779 Acc 0.703\n",
      "[ 11/25] Training Step 100 Loss 0.637 Acc 0.781\n",
      "[ 11/25] Training Step 200 Loss 0.793 Acc 0.750\n",
      "[ 11/25] Training Step 300 Loss 1.052 Acc 0.562\n",
      "[ 11/25] Training Step 400 Loss 0.642 Acc 0.750\n",
      "[ 11/25] Training Step 500 Loss 0.807 Acc 0.719\n",
      "[ 11/25] Training Step 600 Loss 1.106 Acc 0.547\n",
      "[ 11/25] Training Step 700 Loss 0.754 Acc 0.734\n",
      "[ 11/25] Validate Step 015 Loss 0.952 Acc 0.676\n",
      "---------------- Epoch 11 ----------------\n",
      "[ 12/25] Training Step 000 Loss 0.621 Acc 0.797\n",
      "[ 12/25] Training Step 100 Loss 0.715 Acc 0.766\n",
      "[ 12/25] Training Step 200 Loss 0.850 Acc 0.609\n",
      "[ 12/25] Training Step 300 Loss 0.846 Acc 0.734\n",
      "[ 12/25] Training Step 400 Loss 0.594 Acc 0.781\n",
      "[ 12/25] Training Step 500 Loss 0.812 Acc 0.719\n",
      "[ 12/25] Training Step 600 Loss 0.977 Acc 0.656\n",
      "[ 12/25] Training Step 700 Loss 0.856 Acc 0.703\n",
      "[ 12/25] Validate Step 015 Loss 0.936 Acc 0.676\n",
      "---------------- Epoch 12 ----------------\n",
      "[ 13/25] Training Step 000 Loss 0.938 Acc 0.656\n",
      "[ 13/25] Training Step 100 Loss 0.515 Acc 0.875\n",
      "[ 13/25] Training Step 200 Loss 0.875 Acc 0.688\n",
      "[ 13/25] Training Step 300 Loss 0.846 Acc 0.719\n",
      "[ 13/25] Training Step 400 Loss 0.984 Acc 0.750\n",
      "[ 13/25] Training Step 500 Loss 0.604 Acc 0.844\n",
      "[ 13/25] Training Step 600 Loss 0.856 Acc 0.703\n",
      "[ 13/25] Training Step 700 Loss 0.706 Acc 0.750\n",
      "[ 13/25] Validate Step 015 Loss 0.923 Acc 0.691\n",
      "---------------- Epoch 13 ----------------\n",
      "[ 14/25] Training Step 000 Loss 0.846 Acc 0.750\n",
      "[ 14/25] Training Step 100 Loss 0.682 Acc 0.734\n",
      "[ 14/25] Training Step 200 Loss 0.569 Acc 0.828\n",
      "[ 14/25] Training Step 300 Loss 0.905 Acc 0.688\n",
      "[ 14/25] Training Step 400 Loss 0.722 Acc 0.734\n",
      "[ 14/25] Training Step 500 Loss 0.868 Acc 0.734\n",
      "[ 14/25] Training Step 600 Loss 0.467 Acc 0.875\n",
      "[ 14/25] Training Step 700 Loss 0.534 Acc 0.812\n",
      "[ 14/25] Validate Step 015 Loss 0.915 Acc 0.694\n",
      "---------------- Epoch 14 ----------------\n",
      "[ 15/25] Training Step 000 Loss 0.634 Acc 0.719\n",
      "[ 15/25] Training Step 100 Loss 0.556 Acc 0.844\n",
      "[ 15/25] Training Step 200 Loss 0.616 Acc 0.812\n",
      "[ 15/25] Training Step 300 Loss 0.730 Acc 0.750\n",
      "[ 15/25] Training Step 400 Loss 0.845 Acc 0.703\n",
      "[ 15/25] Training Step 500 Loss 0.538 Acc 0.844\n",
      "[ 15/25] Training Step 600 Loss 0.637 Acc 0.781\n",
      "[ 15/25] Training Step 700 Loss 0.726 Acc 0.688\n",
      "[ 15/25] Validate Step 015 Loss 0.910 Acc 0.680\n",
      "---------------- Epoch 15 ----------------\n",
      "[ 16/25] Training Step 000 Loss 0.573 Acc 0.797\n",
      "[ 16/25] Training Step 100 Loss 0.679 Acc 0.797\n",
      "[ 16/25] Training Step 200 Loss 0.681 Acc 0.781\n",
      "[ 16/25] Training Step 300 Loss 0.808 Acc 0.734\n",
      "[ 16/25] Training Step 400 Loss 0.957 Acc 0.641\n",
      "[ 16/25] Training Step 500 Loss 0.854 Acc 0.781\n",
      "[ 16/25] Training Step 600 Loss 0.748 Acc 0.750\n",
      "[ 16/25] Training Step 700 Loss 0.716 Acc 0.750\n",
      "[ 16/25] Validate Step 015 Loss 0.935 Acc 0.682\n",
      "---------------- Epoch 16 ----------------\n",
      "[ 17/25] Training Step 000 Loss 0.671 Acc 0.797\n",
      "[ 17/25] Training Step 100 Loss 0.699 Acc 0.766\n",
      "[ 17/25] Training Step 200 Loss 0.521 Acc 0.844\n",
      "[ 17/25] Training Step 300 Loss 0.641 Acc 0.781\n",
      "[ 17/25] Training Step 400 Loss 0.473 Acc 0.828\n",
      "[ 17/25] Training Step 500 Loss 0.597 Acc 0.781\n",
      "[ 17/25] Training Step 600 Loss 0.602 Acc 0.750\n",
      "[ 17/25] Training Step 700 Loss 0.639 Acc 0.844\n",
      "[ 17/25] Validate Step 015 Loss 0.922 Acc 0.683\n",
      "---------------- Epoch 17 ----------------\n",
      "[ 18/25] Training Step 000 Loss 0.507 Acc 0.844\n",
      "[ 18/25] Training Step 100 Loss 0.566 Acc 0.797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/25] Training Step 200 Loss 0.553 Acc 0.781\n",
      "[ 18/25] Training Step 300 Loss 0.538 Acc 0.828\n",
      "[ 18/25] Training Step 400 Loss 0.459 Acc 0.844\n",
      "[ 18/25] Training Step 500 Loss 0.813 Acc 0.766\n",
      "[ 18/25] Training Step 600 Loss 0.621 Acc 0.828\n",
      "[ 18/25] Training Step 700 Loss 0.799 Acc 0.719\n",
      "[ 18/25] Validate Step 015 Loss 0.916 Acc 0.687\n",
      "---------------- Epoch 18 ----------------\n",
      "[ 19/25] Training Step 000 Loss 0.593 Acc 0.797\n",
      "[ 19/25] Training Step 100 Loss 0.570 Acc 0.781\n",
      "[ 19/25] Training Step 200 Loss 0.673 Acc 0.766\n",
      "[ 19/25] Training Step 300 Loss 0.436 Acc 0.859\n",
      "[ 19/25] Training Step 400 Loss 0.646 Acc 0.703\n",
      "[ 19/25] Training Step 500 Loss 0.617 Acc 0.844\n",
      "[ 19/25] Training Step 600 Loss 0.619 Acc 0.766\n",
      "[ 19/25] Training Step 700 Loss 0.807 Acc 0.750\n",
      "[ 19/25] Validate Step 015 Loss 0.926 Acc 0.687\n",
      "---------------- Epoch 19 ----------------\n",
      "[ 20/25] Training Step 000 Loss 0.547 Acc 0.750\n",
      "[ 20/25] Training Step 100 Loss 0.625 Acc 0.781\n",
      "[ 20/25] Training Step 200 Loss 0.322 Acc 0.953\n",
      "[ 20/25] Training Step 300 Loss 0.569 Acc 0.797\n",
      "[ 20/25] Training Step 400 Loss 0.558 Acc 0.797\n",
      "[ 20/25] Training Step 500 Loss 0.427 Acc 0.859\n",
      "[ 20/25] Training Step 600 Loss 0.601 Acc 0.797\n",
      "[ 20/25] Training Step 700 Loss 0.804 Acc 0.719\n",
      "[ 20/25] Validate Step 015 Loss 0.933 Acc 0.683\n",
      "---------------- Epoch 20 ----------------\n",
      "[ 21/25] Training Step 000 Loss 0.527 Acc 0.844\n",
      "[ 21/25] Training Step 100 Loss 0.411 Acc 0.859\n",
      "[ 21/25] Training Step 200 Loss 0.576 Acc 0.750\n",
      "[ 21/25] Training Step 300 Loss 0.573 Acc 0.859\n",
      "[ 21/25] Training Step 400 Loss 0.332 Acc 0.938\n",
      "[ 21/25] Training Step 500 Loss 0.459 Acc 0.844\n",
      "[ 21/25] Training Step 600 Loss 0.436 Acc 0.875\n",
      "[ 21/25] Training Step 700 Loss 0.722 Acc 0.719\n",
      "[ 21/25] Validate Step 015 Loss 0.952 Acc 0.692\n",
      "---------------- Epoch 21 ----------------\n",
      "[ 22/25] Training Step 000 Loss 0.599 Acc 0.812\n",
      "[ 22/25] Training Step 100 Loss 0.520 Acc 0.844\n",
      "[ 22/25] Training Step 200 Loss 0.525 Acc 0.812\n",
      "[ 22/25] Training Step 300 Loss 0.535 Acc 0.797\n",
      "[ 22/25] Training Step 400 Loss 0.435 Acc 0.828\n",
      "[ 22/25] Training Step 500 Loss 0.414 Acc 0.875\n",
      "[ 22/25] Training Step 600 Loss 0.431 Acc 0.828\n",
      "[ 22/25] Training Step 700 Loss 0.473 Acc 0.781\n",
      "[ 22/25] Validate Step 015 Loss 0.940 Acc 0.693\n",
      "---------------- Epoch 22 ----------------\n",
      "[ 23/25] Training Step 000 Loss 0.592 Acc 0.859\n",
      "[ 23/25] Training Step 100 Loss 0.402 Acc 0.875\n",
      "[ 23/25] Training Step 200 Loss 0.502 Acc 0.812\n",
      "[ 23/25] Training Step 300 Loss 0.469 Acc 0.891\n",
      "[ 23/25] Training Step 400 Loss 0.574 Acc 0.859\n",
      "[ 23/25] Training Step 500 Loss 0.623 Acc 0.734\n",
      "[ 23/25] Training Step 600 Loss 0.717 Acc 0.719\n",
      "[ 23/25] Training Step 700 Loss 0.498 Acc 0.844\n",
      "[ 23/25] Validate Step 015 Loss 0.945 Acc 0.684\n",
      "---------------- Epoch 23 ----------------\n",
      "[ 24/25] Training Step 000 Loss 0.552 Acc 0.844\n",
      "[ 24/25] Training Step 100 Loss 0.563 Acc 0.859\n",
      "[ 24/25] Training Step 200 Loss 0.440 Acc 0.828\n",
      "[ 24/25] Training Step 300 Loss 0.452 Acc 0.812\n",
      "[ 24/25] Training Step 400 Loss 0.303 Acc 0.922\n",
      "[ 24/25] Training Step 500 Loss 0.416 Acc 0.828\n",
      "[ 24/25] Training Step 600 Loss 0.512 Acc 0.859\n",
      "[ 24/25] Training Step 700 Loss 0.446 Acc 0.875\n",
      "[ 24/25] Validate Step 015 Loss 0.956 Acc 0.687\n",
      "---------------- Epoch 24 ----------------\n",
      "[ 25/25] Training Step 000 Loss 0.187 Acc 0.984\n",
      "[ 25/25] Training Step 100 Loss 0.290 Acc 0.906\n",
      "[ 25/25] Training Step 200 Loss 0.474 Acc 0.828\n",
      "[ 25/25] Training Step 300 Loss 0.307 Acc 0.891\n",
      "[ 25/25] Training Step 400 Loss 0.407 Acc 0.875\n",
      "[ 25/25] Training Step 500 Loss 0.253 Acc 0.938\n",
      "[ 25/25] Training Step 600 Loss 0.409 Acc 0.875\n",
      "[ 25/25] Training Step 700 Loss 0.342 Acc 0.906\n",
      "[ 25/25] Validate Step 015 Loss 0.972 Acc 0.686\n",
      "---------------- Testing ----------------\n",
      "[  1/25] Testing Step 156 Loss 0.993 Acc 0.677\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "optimizer = None\n",
    "###############################################################################\n",
    "#                               TODO                                          #\n",
    "###############################################################################          \n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=2, bias=0)),\n",
    "    ('batchnorm1', nn.BatchNorm2d(16)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, bias=0)),\n",
    "    ('batchnorm2', nn.BatchNorm2d(32)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "#     ('conv3', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, bias=0)),\n",
    "#     ('batchnorm3', nn.BatchNorm2d(64)),\n",
    "#     ('relu4', nn.ReLU()),\n",
    "    ('flatten', Flatten()),\n",
    "    ('fc1', nn.Linear(32*7*7, 200, bias=0)),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(200, 10, bias=0))\n",
    "    ]))\n",
    "###############################################################################\n",
    "#                            END TO DO                                        #\n",
    "###############################################################################  \n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=1e-3, momentum=0.9)\n",
    "trainer = Trainer(criterion, optimizer, device)\n",
    "trainer.train_loop(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請解釋你如何建構的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--寫在這裡--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
